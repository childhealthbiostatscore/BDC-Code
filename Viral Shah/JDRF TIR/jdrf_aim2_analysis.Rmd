---
title: "JDRF_Aim2_analysis"
author: "Casey Sakamoto"
date: "2023-03-02"
output: html_document
---

```{r setup, include=FALSE}
library(caret)
library(tidyverse)
library(tidymodels)
library(doParallel)
library(DataExplorer)
library(knitr)
library(lubridate)
library(ggplot2)
```


```{r data up clean, include=FALSE}
# upload data
jdrf_data_clean <- read_csv("S:/Laura/BDC/Projects/Viral Shah/JDRF/Data_Cleaned/jdrf_data_clean.csv")
# list to check by
# import demographics data
Group_1_Demographic_data = read_excel("S:/Laura/BDC/Projects/Viral Shah/JDRF/Data_Raw/13. JDRF_TIR/3. Data Collection/Cleaned Final Data/Group 1/2. Group 1_Demographic data_2-3-2022.xlsx",
                                      na = "NULL") %>%
  rename(Date = "Vital_VisitDate")
# need to account for na = null
# Group_1_Demographic_data =  read_excel("./Data_Raw/Group 1_Demographic data_2-3-2022.xlsx", 
#     col_types = c("numeric", "numeric", "text", 
#         "text", "text", "text", "date", "date", 
#         "numeric", "text", "text", "text", 
#         "date", "numeric", "numeric", "numeric", 
#         "text", "date", "numeric", "text", 
#         "text", "text", "text", "text", "text", 
#         "text", "text"))

Group_2_Demographic_Data = read_excel("S:/Laura/BDC/Projects/Viral Shah/JDRF/Data_Raw/13. JDRF_TIR/3. Data Collection/Cleaned Final Data/Group 2/2. Group 2_ Demographics_6-13-2022.xlsx",
                                      na = "NULL") %>%
  rename(Date = "Vital_VisitDate")
# add group number variable
Group_1_Demographic_data$Group = "Case"
Group_2_Demographic_Data$Group = "Control"
# note there is a comment variable in group 2 not in group 1
Demographic_data = full_join(Group_1_Demographic_data, Group_2_Demographic_Data)
rm(Group_1_Demographic_data, Group_2_Demographic_Data)


# check that each id is in the demogs
jdrf_data_clean = jdrf_data_clean %>% filter(MRN %in% Demographic_data$MRN)
jdrf_a1c = jdrf_data_clean %>% filter(!is.na(visit_num))
# jdrf_a1c = jdrf_a1c %>% group_by(`Study ID`) %>% mutate(visit = ((max(visit_num)+1) - visit_num)) %>% select(-c(visit_num, X))

# annualize data
jdrf_a1c = jdrf_a1c %>% group_by(`Study ID`) %>% filter(!is.na(Date)) %>% mutate(yrs_since_ret = time_length(difftime( `Date of eye exam`,Date),"years"),
                                                                                 YEAR = floor(yrs_since_ret) + 1)

jdrf_a1c = jdrf_a1c %>% select(-c(`First name`, `Last name`, X))


# commented out old var names
# here we are averaging subjects across visits, and then comparing these averages between groups
jdrf_a1c = jdrf_a1c %>% mutate(a1c = case_when(a1c == "televisit" ~ NA_character_,
                                                             a1c == "-" ~ NA_character_,
                                                             TRUE ~ a1c))
jdrf_a1c$a1c = as.numeric(jdrf_a1c$a1c)

# UACR Variable looks terrible
jdrf_a1c = jdrf_a1c %>% mutate(uacr = case_when(str_detect(uacr, "<") ~ (as.character(as.numeric(str_sub(uacr, 2))/2)),
                                                uacr == "NOTE" ~ NA_character_,
                                                uacr == "CANCELLED" ~ NA_character_,
                                                uacr == "SEE COMMENTS" ~ NA_character_,
                                                uacr == "NOTE" ~ NA_character_,
                                                uacr == "LESS THAN 4.6" ~ "2.3",
                                                uacr == "2E-3" ~ ".002",
                                                TRUE ~ uacr))
jdrf_a1c$uacr = as.numeric(jdrf_a1c$uacr)
jdrf_a1c = jdrf_a1c %>% mutate(totalcgmtime = sensor_readings*sensor_interval/(60*24))

# 
#testcgm = cgm %>% filter(cgm$Date %in% jdrf_a1c$Date)
#sum(test)

# total visits
visit_count = jdrf_a1c %>% group_by(`Study ID`) %>%  count(`Study ID`, name = "total_visits")
jdrf_a1c = full_join(jdrf_a1c, visit_count)

# ANNUALLIZED
jdrf_a1c_ann = jdrf_a1c %>% group_by(`Study ID`, YEAR) %>% summarise(mean_a1c = mean(a1c, na.rm = T),
                                                                      mean_tir = mean(tir, na.rm = T),
                                                                      mean_tbr = mean(tbr, na.rm = T),
                                                                      mean_tar = mean(tar, na.rm = T),
                                                                      mean_ttir = mean(ttir, na.rm = T),
                                                                      mean_glucose = mean(mean_glucose, na.rm = T),
                                                                      mean_egfr = mean(egfr, na.rm = T),
                                                                      mean_ldl = mean(ldl, na.rm = T),
                                                                      mean_hdl = mean(hdl, na.rm = T),
                                                                      mean_tc = mean(tc, na.rm = T),
                                                                      mean_uacr = mean(uacr, na.rm = T))

other_vars = jdrf_a1c %>% select(`Study ID`, MRN, Age_DateOfEyeExam, Group, DiabetesDuration_DateOfEyeExam)
jdrf_a1c_ann = left_join(jdrf_a1c_ann, other_vars) %>% distinct()
jdrf_a1c_ann = jdrf_a1c_ann %>% filter(YEAR > 0)
jdrf_a1c_ann$YEAR = factor(jdrf_a1c_ann$YEAR, levels = c(1,2,3,4,5,6,7))
jdrf_a1c_ann$Group = factor(jdrf_a1c_ann$Group, levels = c("Control", "Case"))

rm(Demographic_data)
```

```{r preprocess data for elnet, include=FALSE}


```
# Outstanding Data Problems/Remarks

Variables to include?

Analysis Plan? all I have is "JDRF Aim 2: a new composite CGM metrics for DM retinopathy" 

# Methods

Elastic net was run on the JDRF dataset. Caret and GLMNet packages used to fit model. CGM metrics included in the model selection were:

# Analysis


```{r caret}
testdata = jdrf_a1c %>% ungroup() %>% select(Group, tir, a1c, ttir, mean_glucose, tbr, tar) %>% na.omit()

set.seed(3223)

# Use caret to train the model
cv <- trainControl(method = "cv",
                   number = 5,
                   repeats = 5,
                   allowParallel = T)
# Parallel training (may not be necessary)
# cl <- makePSOCKcluster(detectCores()*0.5)
# registerDoParallel(cl)

elnet <- train(
  Group ~. ,
  data = testdata,
  method = "glmnet",
  preProcess = c("center", "scale"),
  trControl = cv,
  family = "binomial",
  tuneLength = 25,
  allowParallel = T
)
# stopCluster(cl)


# Get the best models
res = elnet$results
kable(head(res[order(res$Accuracy,decreasing = T),],5),row.names = F)


# model prediction
xhat_predicted = predict(elnet, testdata)

mean(xhat_predicted == testdata$Group)


```

Accuracy was used to select the optimal model using the largest value.
The final values used for the model were alpha = 0.1 and lambda = 0.03520814.


Accuracy? was 0.658 using model on the dataset