---
title: "Daily Predictors for Diabetes Management"
author: "Tim Vigers & Laura Pyle"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  html_document:
    number_sections: yes
    toc: yes
    toc_depth: 2
    toc_float: yes
---

```{r setup, include=FALSE}
library(Hmisc)
library(arsenal)
library(skimr)
library(knitr)
library(tidyverse)
library(lubridate)
library(redcapAPI)
library(nlme)
library(glmmLasso)
library(parallel)
library(caret)
library(glmnet)
knitr::opts_chunk$set(echo = F,cache = T)
home_dir = ifelse(.Platform$OS.type != "unix","Z:/PEDS/RI Biostatistics Core/Shared/Shared Projects/Laura/BDC/Projects",
                  "/mnt/UCD/PEDS/RI Biostatistics Core/Shared/Shared Projects/Laura/BDC/Projects")
knitr::opts_knit$set(root.dir = home_dir)
set.seed(1017)
```

```{r clean data}
source("~/GitHub/BDC-Code/Laurel Messer/Daily Predictors/clean_data.r")
# Combine race columns
race_cols = paste0("pt_race___",1:6)
races = c("White","Black or African American","American Indian or Alaskan Native",
          "Asian","Native Hawaiian or Pacific Islander","Other")
data$race = apply(data[,race_cols], 1, function(r){
  paste0(races[which(r == 1)],collapse = ", ")
})
# Calculate age and duration
data$age = as.numeric(ymd(data$pt_visit_date) - ymd(data$pt_dob))/365.25
data$duration = as.numeric(ymd(data$pt_visit_date) - ymd(data$dxdate))/365.25
# ID as factor for glmmLasso
data$record_id = as.factor(data$record_id)
```

# Participant Characteristics

```{r results = 'asis'}
# Get first row for each person
demographics = data %>% group_by(record_id) %>% filter(row_number() == 1)
# Table 
t1 = tableby(~ age + duration + pt_a1c + pt_baseline1.factor + pt_baseline5.factor + 
               pt_gender.factor + race + pt_eth.factor + p1_hedu.factor + 
               p2_hedu.factor,demographics)
# Labels
new_labels = list(age = "Age", duration = "Diabetes Duration", pt_a1c = "Baseline HbA1c",
                  pt_baseline1.factor = "Pump Hx",pt_baseline5.factor = "CGM Hx",
                  pt_gender.factor = "Gender", race = "Race", pt_eth.factor = "Ethnicity", 
                  p1_hedu.factor = "Parent 1 Education", p2_hedu.factor = "Parent 2 Education")
summary(t1,labelTranslations = new_labels)
```

# Regularization (LASSO) Results

```{r}
# Correlation between engagement survey items and subscores and:
#   Number of insulin boluses
#   Average glucose level
#   Percent time glucose levels 70-180 mg/dl (“Time-in-Range”, TIR)
#   Goal Survey Scores
morning_items = colnames(data)[grep("esq\\d+$",colnames(data))]
evening_items = colnames(data)[grep("esq\\d+_eve$",colnames(data))]
# Outcomes
goal_survey = c("n_highalerts","dm_caretime","dm_thinktime","gsq1","gsq2","gsq3")
outcomes = c("boluses","smg","tir",goal_survey)
# ID Variables
id_vars = c("record_id","redcap_event_name","es_datetimecapture")
# Optimal lambda function = needs id variables, one outcome, and predictors (nothing else)
lambda_cv = function(df,outcome_name,folds = 5,core_ratio = 0.5,n_lambda = 50){
  # Make model formula
  pred = colnames(df)[which(!colnames(df) %in% c(outcome_name,id_vars))]
  form = as.formula(paste(outcome_name,"~",paste(pred,collapse = "+")))
  # K-fold cross validation
  k = folds
  # Fit a starting model to speed up glmmLasso
  start_mod = lme(form,random = ~1|record_id,data = df)
  # Need to account for excluded data in starting values - replace with 0
  start_rand = matrix(nrow = length(levels(df$record_id)),ncol = 1,
                      dimnames = list(1:length(levels(df$record_id)),"(Intercept)"))
  start_rand[,1] = 0
  start_rand[rownames(start_mod$coefficients$random$record_id),] = 
    start_mod$coefficients$random$record_id[,1]
  # Vector of starting values
  start_vals = as.numeric(c(start_mod$coefficients$fixed,start_rand))
  # Select min and max lambda values to try using cv.glmnet on baseline values
  t = df %>% group_by(record_id) %>% filter(row_number()==1)
  lambdas = cv.glmnet(as.matrix(t[,pred]),as.matrix(t[,outcome_name]))$lambda
  lambdas = seq(min(lambdas),max(lambdas),length.out = n_lambda)
  # Try all the different lambdas
  cl <- makeCluster(detectCores()*core_ratio, type='PSOCK')
  outcome_name = outcome_name
  clusterExport(cl,list('groupKFold','glmmLasso','R2','RMSE','MAE',
                        'outcome_name','form','start_vals','lambdas','df','k'),
                envir=environment())
  metrics = parLapply(cl,lambdas, function(l){
    # Cross validate
    sample <- groupKFold(df$record_id,k = k)
    cv = lapply(sample, function(s){
      # Training from group K
      train  <- df[s, ]
      # Test set
      test <- df[-s, ]
      # Fit - fairly different model results with REML vs. EM, but REML is really slow.
      # Use EM for cross validation, REML for final model fit.
      mod <- try(suppressWarnings(glmmLasso(form, rnd = list(record_id=~1),
                                            data = train,lambda=l,
                                            control = list(start = start_vals))),
                 silent = T)
      if(class(mod)!="try-error"){
        # Model performance
        predicted <- predict(mod, test)
        data.frame(R2 = R2(predicted, test[,outcome_name]),
                   RMSE = RMSE(predicted, test[,outcome_name]),
                   MAE = MAE(predicted, test[,outcome_name]))
      } else {
        data.frame(R2 = NA,
                   RMSE = NA,
                   MAE = NA)
      }
    })
    cv = do.call(rbind,cv)
    return(c(l,colMeans(cv,na.rm = T)))
  })
  stopCluster(cl)
  metrics = data.frame(do.call(rbind,metrics))
  colnames(metrics)[1] = "lambda"
  return(metrics)
}
```

## Number of boluses

### Morning survey

```{r echo=TRUE}
# Get morning variables
bolus_morning = data[,c(id_vars,morning_items,"boluses")]
bolus_morning = bolus_morning[complete.cases(bolus_morning),]
# CV for lambda values
# Time this code
ptm <- proc.time()
lambda_perf = lambda_cv(df = bolus_morning,outcome_name = "boluses",n_lambda = 20)
proc.time() - ptm
best_lambda = lambda_perf$lambda[which.min(lambda_perf[,"RMSE"])]
```

### Evening survey


# Questions for Laura

1. How many Lambda values to check?
2. Which metric should we use for picking lambda? RMSE?

# Questions for Laurel and Emily

1. How should we combine levels of race and parent education? White vs. non-white? Above a bachelor's degree vs. bachelor's and below?
