---
title: "TEDDY Multi-Assay Analysis"
author: "Tim Vigers & Laura Pyle"
date: "`r format(Sys.time(), '%d %B %Y')`"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(pheatmap)
library(skimr)
library(glmnet)
library(knitr)
library(igraph)
library(networkD3)
library(car)
library(performance)
library(caret)
library(parallel)
library(doParallel)
knitr::opts_chunk$set(echo = FALSE,cache = TRUE)
home_dir = ifelse(.Platform$OS.type != "unix",
                  "Z:/PEDS/RI Biostatistics Core/Shared/Shared Projects/Laura/BDC/Projects/Howard Davidson/TEDDY data",
                  "~/UCD/PEDS/RI Biostatistics Core/Shared/Shared Projects/Laura/BDC/Projects/Howard Davidson/TEDDY data")
knitr::opts_knit$set(root.dir = home_dir)
rm(home_dir)
```

```{r data}
load("./Data_Clean/time_0.RData")
```

```{r functions}
# Clean data (standard pipeline)
data_preprocces = function(df,missing_cutoff = 0.8,cv_cutoff = NULL,
                           log_transform = F,scale = T,
                           outcome = "y",id_cols = c("id","time")){
  # Get predictors
  pred = colnames(df)[which(!(colnames(df) %in% c(outcome,id_cols)))]
  # Predictors with too much missing data
  if(!is.null(missing_cutoff)){
    missing = pred[which(colMeans(is.na(df[,pred]))>=missing_cutoff)]
  } else {missing = c()}
  # Predictors with high CV
  if(!is.null(cv_cutoff)){
    cvs = sapply(df[,pred], function(c){
      sd(c,na.rm = T) / mean(c,na.rm = T)
    })
    high_cv = pred[which(cvs > cv_cutoff)]
  } else {high_cv = list()}
  # Remove columns
  initial_set = setdiff(pred,c(missing,high_cv))
  df = df[,c(id_cols,initial_set,outcome)]
  # Remove rows with all missing
  rows_missing = rowSums(is.na(df[,initial_set]))
  df = df[which(rows_missing < length(initial_set)),]
  # Log transform
  if(log_transform){
    df[,initial_set] = lapply(df[,initial_set],log)
    if(any(df == -Inf)){warning("-Inf present after log transform")}
  }
  # Scale
  if(scale){
    df[,initial_set] = lapply(df[,initial_set],scale)
  }
  return(df)
}
# Cluster variables according to DIFAcTO pipeline.
# If optimize_corr = T, this will override the manual corr_cutoff. Correlation
# cutoff should be optimized for all assays, but does not need to be run every time.
corr_cluster = function(df,parallel_ratio = 0.5,folds = 5,
                        outcome = "y",id_cols = c("id","ID","time"),
                        optimize_corr = T, corr_cutoff = NULL,
                        heatmap = T,heatmap_params = list(show_rownames = T,show_colnames = T),
                        network = T){
  # Get predictors
  pred = setdiff(colnames(df),c(id_cols,outcome))
  # Outcome is binary
  df[,outcome] = factor(df[,outcome])
  # Complete
  df = df[complete.cases(df),]
  # Correlations between predictors
  corr_mat = cor(df[,pred],use = "pairwise.complete.obs")
  # Get pairs
  var_cor = corr_mat*lower.tri(corr_mat)
  # Find best correlation cutoff
  if(optimize_corr){
    rs = seq(0,1,by = 0.01)
    # Parallel
    cl <- makeCluster(detectCores()*parallel_ratio,type = "FORK")
    model_perf = parLapply(cl,rs, function(r){
      # Correlation cutoff
      check_cor = which(abs(var_cor) >= r, arr.ind=TRUE)
      # Convert correlated pairs into graph clusters
      graph_cor = graph.data.frame(check_cor, directed = FALSE)
      # Get names
      groups_cor = split(unique(as.vector(check_cor)), clusters(graph_cor)$membership)
      groups = lapply(groups_cor,FUN=function(list_cor){rownames(var_cor)[list_cor]})
      # Find highest correlation within each group
      # Use logistic model estimate instead of correlation
      best_cor = lapply(groups, function(g){
        assocs = lapply(g, function(v){
          form = as.formula(paste0(outcome,"~",v))
          mod = glm(form,df,family = "binomial")
          coefs = summary(mod)$coefficients
          return(abs(coefs[2,1]))
        })
        return(g[which.max(assocs)])
      })
      best_cor = as.character(best_cor)
      if(length(best_cor)>0){
        # CV with caret
        set.seed(1017)
        cv = trainControl(method = "cv",number = folds)
        # Model
        form = as.formula(paste0(outcome,"~",paste0(best_cor,collapse = "+")))
        # CV
        mod = train(
          form, data = df,
          method = "glm",
          family = "binomial",
          trControl = cv,
          tuneLength = 25
        )
        return(mod$results$Accuracy)
      } else {return(NA)}
    })
    stopCluster(cl)
    opt_r = rs[which.max(model_perf)]
  } else {opt_r = corr_cutoff}
  # final groups
  # Correlation cutoff
  check_cor = which(abs(var_cor) >= opt_r, arr.ind=TRUE)
  # Convert correlated pairs into graph clusters
  graph_cor = graph.data.frame(check_cor, directed = FALSE)
  # Get names
  groups_cor = split(unique(as.vector(check_cor)), clusters(graph_cor)$membership)
  groups = lapply(groups_cor,FUN=function(list_cor){rownames(var_cor)[list_cor]})
  # Find highest correlation within each group
  best_cor = lapply(groups, function(g){
    assocs = lapply(g, function(v){
      form = as.formula(paste0(outcome,"~",v))
      mod = glm(form,df,family = "binomial")
      coefs = summary(mod)$coefficients
      return(abs(coefs[2,1]))
    })
    return(g[which.max(assocs)])
  })
  best_cor = as.character(best_cor)
  # Plots
  if(heatmap){
    heatmap_params[["mat"]] = corr_mat
    heat = do.call(pheatmap,heatmap_params)
  }
  if(network){
    # Interactive plot
    int_plot_df = check_cor
    int_plot_df[,1] = rownames(corr_mat)[int_plot_df[,1]]
    int_plot_df[,2] = colnames(corr_mat)[as.numeric(int_plot_df[,2])]
    # Node DF
    nodes <- data.frame(name = unique(c(int_plot_df[,1], int_plot_df[,2])), 
                        stringsAsFactors = FALSE)
    nodes$id <- 0:(nrow(nodes) - 1)
    # Edges DF
    edges <- int_plot_df %>% data.frame(.) %>%
      left_join(nodes, by = c("row" = "name")) %>%
      select(-row) %>%
      rename(source = id) %>%
      left_join(nodes, by = c("col" = "name")) %>%
      select(-col) %>%
      rename(target = id)
    # Plot parameters
    edges$width <- 1
    # Color by group
    nodes$group = sapply(nodes$name, function(n){
      l = lapply(groups, function(x){
        n %in% x
      })
      as.numeric(which(l == TRUE))
    })
    # Plot
    p = forceNetwork(Links = edges, Nodes = nodes, 
                     Source = "source",
                     Target = "target",
                     NodeID ="name",
                     Group = "group",
                     Value = "width",
                     zoom = TRUE,
                     opacity = 1,
                     height = 720,
                     width = 720)
  }
  if(heatmap & network){
    return(list("best" = best_cor,"r_cutoff" = opt_r,"heatmap" = heat,"network" = p))
  } else if (heatmap & !network){
    return(list("best" = best_cor,"r_cutoff" = opt_r,"heatmap" = heat))
  } else if (!heatmap & network){
    return(list("best" = best_cor,"r_cutoff" = opt_r,"network" = p))
  } else {return("best" = best_cor,"r_cutoff" = opt_r,)}
}
```

# DIFAcTO

## Methods

1. Columns with >= 80% missing data were dropped. 
2. Rows missing all of the retained variables from step 1 were dropped.
3. Remaining variables were scaled prior to analysis.
4. For correlation cutoffs from 0 to 1 (by 0.01), predictors were clustered based on correlation. Within each cluster, the variable with the strongest association with the outcome was selected to enter the model. 
5. Normalized RMSE was used to compare model performance between correlation cutoffs. 
6. Variables selected using the optimal correlation cutoff continued on to the lasso. 
7. A lasso model was fit using the variables selected from previous steps. Using the lambda value that results in minimum error selects 0 predictors. So instead we used the lambda value that results in the largest model that is still within 1SD of the minimum error, and fits without numerical probabilities of 0 or 1 occurring.

# Predictor Clustering

## Carotenoids

```{r}
carotenoids = data_preprocces(X$carotenoids)
carotenoids_best = corr_cluster(carotenoids)
carotenoids_best$heatmap
carotenoids_best$network
kable(carotenoids_best$best,col.names = "Selected variables")
```

The optimal $\rho$ cutoff was `r carotenoids_best$r_cutoff` based on normalized RMSE.

## Fatty acids

```{r}
fa = data_preprocces(X$fatty_acids)
fa_best = corr_cluster(fa)
fa_best$heatmap
fa_best$network
kable(fa_best$best,col.names = "Selected variables")
```

The optimal $\rho$ cutoff was `r fa_best$r_cutoff` based on normalized RMSE.

## Metabolomics

```{r}
metab = data_preprocces(X$metabolomics)
metab_best = corr_cluster(metab,heatmap_params = list(show_rownames = F,show_colnames = F))
metab_best$heatmap
metab_best$network
kable(metab_best$best,col.names = "Selected variables")
```

The optimal $\rho$ cutoff was `r metab_best$r_cutoff` based on normalized RMSE.

## Transcriptomics

```{r eval=FALSE}
transcript = data_preprocces(X$transcriptomics)
transcript_best = corr_cluster(transcript,heatmap=F,network=F,optimize_corr = T)
kable(transcript_best,col.names = "Selected variables")
```

## Negative lipidomics

```{r}
negative = data_preprocces(X$negative_lipidomics,cv_cutoff = 0.2)
negative_best = corr_cluster(negative,heatmap_params = list(show_rownames = F,show_colnames = F))
negative_best$heatmap
negative_best$network
kable(negative_best$best,col.names = "Selected variables")
```

The optimal $\rho$ cutoff was `r negative_best$r_cutoff` based on normalized RMSE.

## Positive lipidomics

```{r}
positive = data_preprocces(X$positive_lipidomics)
positive_best = corr_cluster(positive,heatmap_params = list(show_rownames = F,show_colnames = F))
positive_best$heatmap
positive_best$network
kable(positive_best$best,col.names = "Selected variables")
```

The optimal $\rho$ cutoff was `r positive_best$r_cutoff` based on normalized RMSE.

# Lasso

In addition to the selected variables from the 'omics assays above, all variables from assays with 3 or fewer measures (ascorbic acid, cholesterol, growth, etc.) were included in the lasso. 

```{r}
folds = 5
# All variables selected above
lasso_vars = c("ascorbic_acid",carotenoids_best$best,"cholesterol",
               fa_best$best,metab_best$best,transcript_best$best,
               "height_cm","weight_kg","agemos",negative_best$best,positive_best$best,
               "alphatocopherol","gammatocopherol","vitamin_d")
lasso_form = as.formula(paste0("y~",paste0(lasso_vars,collapse = "+")))
# Pull out selected variables
smaller_dfs = lapply(X, function(d){
  d = d[,which(colnames(d) %in% c("ID","id","time","y",lasso_vars))]
})
# Combine into single dataframe
df = full_join(smaller_dfs[[1]],smaller_dfs[[2]],by = c("ID"="id","time","y"))
df = full_join(df,smaller_dfs[[3]],by = c("ID","y","time"))
df = full_join(df,smaller_dfs[[4]],by = c("ID"="id","time","y"))
df = full_join(df,smaller_dfs[[5]],by = c("ID"="id","time","y"))
df = full_join(df,smaller_dfs[[6]],by = c("ID"="id","time","y"))
df = full_join(df,smaller_dfs[[7]],by = c("ID"="id","time","y"))
df = full_join(df,smaller_dfs[[8]],by = c("ID"="id","time","y"))
df = left_join(df,smaller_dfs[[9]],by = c("ID"="id","time","y"))
df[,grep("\\.y",colnames(df))] = NULL
colnames(df)[grep("\\.x",colnames(df))] = 
  sub("\\.x","",colnames(df)[grep("\\.x",colnames(df))])
df = left_join(df,smaller_dfs[[10]],by = c("ID"="id","time","y"))
df = left_join(df,smaller_dfs[[11]],by = c("y", "ID", "time"))
# Remove missing
lasso_df = df[complete.cases(df),]
lasso_df$y = factor(lasso_df$y)
# CV with caret
set.seed(1017)
cv = trainControl(method = "cv",number = folds)
# Model
form = as.formula(paste0("y~",paste0(lasso_vars,collapse = "+")))
# Parallel
cl = makePSOCKcluster(folds)
registerDoParallel(cl)
mod = train(
  form, data = lasso_df,
  method = "glmnet",
  family = "binomial",
  trControl = cv,
  tuneLength = 25
)
stopCluster(cl)
# Best lambda keeping alpha at 1
best = mod$results[mod$results$alpha == 1,]
best = best[best$Accuracy == max(best$Accuracy),]
# Fit
mod = glmnet(x = data.matrix(lasso_df[,lasso_vars]), 
             y = factor(lasso_df[,"y"]),family = "binomial",
             alpha = 1,lambda = best$lambda)
kable(rownames(coef(mod))[which(coef(mod) != 0)],col.names = "Selected variables")
```

# Elasticnet

## Methods

1. Columns with >= 80% missing data were dropped. 
2. Rows missing all of the retained variables from step 1 were dropped.
3. Remaining variables were scaled prior to analysis.
4. Due to missing data problems, an elasticnet was run for each assay separately. 

```{r elasticnet function}
elastic = function(df,folds = 5,outcome = "y",id_cols = c("id","ID","time")){
  # Outcome 
  df[,outcome] = factor(df[,outcome])
  # Predictors
  pred = setdiff(colnames(df),c(id_cols,outcome))
  # Complete
  df = df[complete.cases(df),]
  # Formula
  form = as.formula(paste0(outcome,"~",paste0(pred,collapse = "+")))
  # Caret CV
  set.seed(1017)
  cv = trainControl(method = "cv",number = folds)
  # Parallel
  cl = makePSOCKcluster(folds)
  registerDoParallel(cl)
  mod = train(
    form, data = df,
    method = "glmnet",
    family = "binomial",
    trControl = cv,
    tuneLength = 25
  )
  stopCluster(cl)
  best = mod$bestTune
  # Get variables
  # Re-fit
  df[,outcome]
  m = glmnet(data.matrix(df[,pred]),data.matrix(df[,outcome]),
             alpha = best$alpha,lambda = best$lambda)
  coefs = coef(m)
  selected = rownames(coefs)[which(coefs != 0 & rownames(coefs) != "(Intercept)")]
  return(selected)
}
```

## Carotenoids

```{r}
carot_elastic = elastic(carotenoids)
kable(carot_elastic,col.names = "Selected variables")
```

## Fatty acids

```{r}
fa_elastic = elastic(fa)
kable(fa_elastic,col.names = "Selected variables")
```

## Metabolomics

```{r}
metab_elastic = elastic(metab)
kable(metab_elastic,col.names = "Selected variables")
```

## Transcriptomics

```{r eval=FALSE}
trans_elastic = elastic(transcript)
kable(trans_elastic,col.names = "Selected variables")
```

## Negative lipidomics

```{r}
neg_elastic = elastic(negative)
kable(neg_elastic,col.names = "Selected variables")
```

## Positive lipidomics

```{r}
pos_elastic = elastic(positive)
kable(pos_elastic,col.names = "Selected variables")
```

## Lasso the lasso (more accurately elasticnet the elasticnet)

```{r}
# All variables selected above
elastic_vars = c("ascorbic_acid",carot_elastic,"cholesterol",
                 fa_elastic,metab_elastic,trans_elastic,
                 "height_cm","weight_kg","agemos",neg_elastic,pos_elastic,
                 "alphatocopherol","gammatocopherol","vitamin_d")
elastic_form = as.formula(paste0("y~",paste0(elastic_vars,collapse = "+")))
# Pull out selected variables
smaller_dfs = lapply(X, function(d){
  d = d[,which(colnames(d) %in% c("ID","id","time","y",elastic_vars))]
})
# Combine into single dataframe
df = full_join(smaller_dfs[[1]],smaller_dfs[[2]],by = c("ID"="id","time","y"))
df = full_join(df,smaller_dfs[[3]],by = c("ID","y","time"))
df = full_join(df,smaller_dfs[[4]],by = c("ID"="id","time","y"))
df = full_join(df,smaller_dfs[[5]],by = c("ID"="id","time","y"))
df = full_join(df,smaller_dfs[[6]],by = c("ID"="id","time","y"))
df = full_join(df,smaller_dfs[[7]],by = c("ID"="id","time","y"))
df = full_join(df,smaller_dfs[[8]],by = c("ID"="id","time","y"))
df = left_join(df,smaller_dfs[[9]],by = c("ID"="id","time","y"))
df[,grep("\\.y",colnames(df))] = NULL
colnames(df)[grep("\\.x",colnames(df))] = 
  sub("\\.x","",colnames(df)[grep("\\.x",colnames(df))])
df = left_join(df,smaller_dfs[[10]],by = c("ID"="id","time","y"))
df = left_join(df,smaller_dfs[[11]],by = c("y", "ID", "time"))
# Remove missing
elastic_df = df[complete.cases(df),]
elastic_df$y = factor(elastic_df$y)
# CV with caret
set.seed(1017)
cv = trainControl(method = "cv",number = folds)
# Model
form = as.formula(paste0("y~",paste0(elastic_vars,collapse = "+")))
# Parallel
cl = makePSOCKcluster(folds)
registerDoParallel(cl)
mod = train(
  form, data = elastic_df,
  method = "glmnet",
  family = "binomial",
  trControl = cv,
  tuneLength = 25
)
stopCluster(cl)
# Best lambda keeping alpha at 1
best = mod$results[mod$results$alpha == 1,]
best = best[best$Accuracy == max(best$Accuracy),]
# Fit
mod = glmnet(x = data.matrix(elastic_df[,elastic_vars]), 
             y = factor(elastic_df[,"y"]),family = "binomial",
             alpha = 1,lambda = best$lambda)
kable(rownames(coef(mod))[which(coef(mod) != 0)],col.names = "Selected variables")
```
