---
title: "Simulating Metabolomic Data"
author: "Tim Vigers & Laura Pyle"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  html_document:
    number_sections: yes
    toc: yes
    toc_depth: 2
    toc_float: yes
---

```{r setup, include=FALSE}
library(randcorr)
library(MASS)
library(igraph)
library(parallel)
library(performance)
library(knitr)
knitr::opts_chunk$set(echo = TRUE)
```

# Functions

```{r}
# Cluster variables according to DIFAcTO pipeline.
# If optimize_corr = T, this will override the manual corr_cutoff. Correlation
# cutoff should be optimized for all assays, but does not need to be run every time.
corr_cluster = function(df,folds = 5,outcome = "y",optimize_corr = T, 
                        rseq = seq(0,1,by = 0.01),corr_cutoff = NULL){
  require(igraph)
  require(caret)
  # Get predictors
  pred = setdiff(colnames(df),outcome)
  # Correlations between predictors
  corr_mat = cor(df[,pred],use = "pairwise.complete.obs")
  # Get pairs
  var_cor = corr_mat*lower.tri(corr_mat)
  # Find best correlation cutoff
  if(optimize_corr){
    rs = rseq
    model_perf = lapply(rs, function(r){
      # Correlation cutoff
      check_cor = which(abs(var_cor) >= r, arr.ind=TRUE)
      # Convert correlated pairs into graph clusters
      graph_cor = graph.data.frame(check_cor, directed = FALSE)
      # Get names
      groups_cor = split(unique(as.vector(check_cor)), clusters(graph_cor)$membership)
      groups = lapply(groups_cor,FUN=function(list_cor){rownames(var_cor)[list_cor]})
      # Find highest correlation within each group
      # Use logistic model estimate instead of correlation
      best_cor = lapply(groups, function(g){
        assocs = lapply(g, function(v){
          form = as.formula(paste0(outcome,"~",v))
          mod = lm(form,df)
          coefs = summary(mod)$coefficients
          return(abs(coefs[2,1]))
        })
        return(g[which.max(assocs)])
      })
      best_cor = as.character(best_cor)
      if(length(best_cor)>0){
        # CV with caret
        set.seed(1017)
        cv = trainControl(method = "cv",number = folds)
        # Model
        form = as.formula(paste0(outcome,"~",paste0(best_cor,collapse = "+")))
        # CV
        mod = train(
          form, data = df,
          method = "lm",
          trControl = cv,
          tuneLength = 25
        )
        return(mod$results$RMSE)
      } else {return(NA)}
    })
    opt_r = rs[which.max(model_perf)]
  } else {opt_r = corr_cutoff}
  # final groups
  # Correlation cutoff
  check_cor = which(abs(var_cor) >= opt_r, arr.ind=TRUE)
  # Convert correlated pairs into graph clusters
  graph_cor = graph.data.frame(check_cor, directed = FALSE)
  # Get names
  groups_cor = split(unique(as.vector(check_cor)), clusters(graph_cor)$membership)
  groups = lapply(groups_cor,FUN=function(list_cor){rownames(var_cor)[list_cor]})
  # Find highest correlation within each group
  best_cor = lapply(groups, function(g){
    assocs = lapply(g, function(v){
      form = as.formula(paste0(outcome,"~",v))
      mod = lm(form,df)
      coefs = summary(mod)$coefficients
      return(abs(coefs[2,1]))
    })
    return(g[which.max(assocs)])
  })
  best_cor = as.character(best_cor)
  # Results
  return(list("best" = best_cor,"r_cutoff" = opt_r))
}
```

```{r}
elasticnet = function(df,folds = 5,outcome = "y",n_alphas = 10,n_lambdas = 100,
                      out = "1se.error"){
  require(ensr)
  X = data.matrix(df[,setdiff(colnames(df),outcome)])
  Y = data.matrix(df[,outcome])
  # Grid search
  list2env(list(X=X,Y=Y,n_alphas=n_alphas,n_lambdas=n_lambdas,folds=folds),.GlobalEnv)
  e = ensr(X,Y,alphas = seq(0, 1, length = n_alphas),nlambda = n_lambdas,
           nfolds = folds,parallel = T)
  # Get lambda and alpha
  res = summary(e)
  min_err = min(res$cvm,na.rm = T)
  se_err = sd(res$cvm,na.rm = T)/sqrt(sum(!is.na(res$cvm)))
  if (out == "min.error"){
    good_mods = which.min(res$cvm)
  } else if (out == "1se.error"){
    good_mods = which(res$cvm <= (min_err + se_err))
  }
  params = data.frame(res[good_mods,])
  params = params[which(params$nzero == min(params$nzero)),]
  params = params[which.min(params$cvm),]
  # Refit models to get selected parameters (the coef() function output for caret is confusing)
  a = params$alpha
  l = params$lambda
  mod = glmnet(y = Y,x = X,alpha = a,lambda = l)
  selected = as.matrix(coef(mod))
  selected = rownames(selected)[selected[,1] != 0]
  selected = selected[selected != "(Intercept)"]
  return(as.numeric(sub("X","",selected)))
}
```

```{r warning=FALSE}
# N is the number of metabolites, and n is the number of samples
# p_con controls likelihood of connected nodes
# sd_mean and sd_sd determine the parameters of the normal distribution that the 
# metabolite standard deviations are drawn from
# mean_mean and mean_sd determine the parameters of the normal distribution that the 
# metabolite means are drawn from
sim_data = function(N = 50, n = 1000,p_con = 0.02,
                    sd_mean = 10,sd_sd = 1,
                    mean_mean = 100,mean_sd = 10,
                    err_mean = 0,err_sd = 1,
                    seed = 1017){
  set.seed(seed)
  # Random correlation matrix
  r = randcorr(N)
  # Set some correlations to 0
  net = matrix(sample(0:1, N^2, replace=TRUE, prob=c(1-p_con,p_con)), nc=N)
  r = net*r
  # Make symmetric
  l = lower.tri(r)*r
  u = t(l)
  r = l + u
  diag(r) = 1
  # Correlation matrix to covariance
  # No 0s in SD!
  sds = round(rnorm(N,mean = sd_mean,sd = sd_sd))
  # diag(S)%*%R%*%diag(S) is covariance where S is SD vector
  cov = diag(sds) %*% r %*% diag(sds)
  # Means
  mus = round(rnorm(N,mean = mean_mean,sd = mean_sd))
  sim <- data.frame(mvrnorm(n,mus,cov)) 
  # Outcome related to 3 correlated metabolite pairs
  met = which(r!=0,arr.ind = T)
  met = met[which(met[,1] != met[,2]),]
  met = met[sample(1:nrow(met),3),]
  met = unique(as.vector(met))
  sim$y = apply(sim[,met],1,function(r){
    sum(r) + rnorm(1,0,1)
  })
  return(list("simulated_data" = sim,"true_metabs" = met))
}
```

```{r}
# Jaccard similarity
jaccard <- function(a, b) {
  intersection = length(intersect(a, b))
  union = length(a) + length(b) - intersection
  return (intersection/union)
}
# RMSE
rmse = function(mod1,mod2){
  
}
```

# Comparison example

```{r}
# Simulate multiple datasets
sims = lapply(1:100, function(i){
  t = sim_data(seed = i)
  return(t)
})
# Check approaches
cl = makeForkCluster(0.5*detectCores())
t = parLapply(cl,sims, function(s){
  d = s$simulated_data
  # Difacto
  difacto = corr_cluster(d)
  difacto = as.numeric(sub("X","",difacto$best))
  # ElasticNet
  elastic = elasticnet(d)
  # RMSE
  difacto_mod = lm(as.formula(paste0("y~",paste0("X",difacto,collapse = "+"))),d)
  elastic_mod = lm(as.formula(paste0("y~",paste0("X",elastic,collapse = "+"))),d)
  # Results
  return(list(
    # Agreement
    "elastic_jacc" = jaccard(elastic,s$true_metabs),
    "difacto_jacc" = jaccard(difacto,s$true_metabs),
    # RMSE
    "elastic_rmse" = rmse(elastic_mod),"difacto_rmse" = rmse(difacto_mod)))
})
stopCluster(cl)
```

# Limitations

1. DIFAcTO was designed for continuous outcomes and features, so for the abstract we had to make some minor changes to work with our binary outcome.
2. The DIFAcTO code was difficult to run on anything but the example data, so we wrote custom code to reproduce the pipeline. There may be important differences in our code (clustering algorithm, etc.), but the overall idea is the same.
3. We assume a multivariate normal distribution for our features, and a linear model with no interactions or polynomial trends. 
4. So many parameters! Ours were chosen based on COPD gene, but there is no gold standard for metabolomics data.
