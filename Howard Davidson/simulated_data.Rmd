---
title: "Simulating Metabolomic Data"
author: "Tim Vigers & Laura Pyle"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  html_document:
    number_sections: yes
    toc: yes
    toc_depth: 2
    toc_float: yes
---

```{r setup, include=FALSE}
library(randcorr)
library(MASS)
library(parallel)
library(performance)
library(knitr)
knitr::opts_chunk$set(echo = TRUE,cache = TRUE)
```

# COPD Gene

```{r}
# Import and clean COPD gene data
copd20 = read.delim("~/Documents/Work/Metabolomics/COPD Gene/ST000601_AN000920_Results.txt")
copd20 = copd20[-1,]
rownames(copd20) = copd20$Compound

copd21 = read.delim("~/Documents/Work/Metabolomics/COPD Gene/ST000601_AN000921_Results.txt")
copd21 = copd21[-1,]
rownames(copd21) = copd21$Compound

copd = data.frame(rbind(copd20,copd21))
copd[,c("Retention.Time","Mass","Compound")] = NULL
copd = data.matrix(copd)
# Get means and SDs of metabolites
means = apply(copd,1,mean)
sds = apply(copd,1,sd)
# Plots
hist(means)
hist(sds)
heatmap(cor(copd))
# Use age as the outcome for univariate associations
copd_info = read.csv("~/Documents/Work/Metabolomics/COPD Gene/ST000601_AN000921_info.csv")
copd_info$ID = paste0("X",copd_info$ID)
age = matrix(copd_info$Age)
copd = data.frame(t(copd))
copd2 = copd[copd_info$ID,]
# Get betas and error from univariate models
betas = sapply(copd, function(m){
  mod = lm(age~m)
  return(summary(mod)$coefficients[2,1])
})
epsilon_resid = unlist(lapply(copd, function(m){
  mod = lm(age~m)
  return(residuals(mod))
}))
# Plots
hist(betas)
hist(epsilon_resid)
```

- To find reasonable parameters for simulated data, we calculated the mean and standard deviation for each metabolite in the COPD Gene dataset. For the sake of simplicity, simulated means are drawn from a $N(1500,830)$ distribution and simulated SDs are drawn from a $U(1,500)$ distribution (to prevent 0s and negatives).

- There does not appear to be much correlation structure in COPD Gene, so we only looked at a random correlation matrix. 

- To find appropriate beta values for the simulated model, we regressed each metabolite from COPD gene on age and examined the distribution of univariate beta values. The beta values appeared to be approximately $N(0.002,0.04)$.

- To find appropriate values for the simulated model error, we calculated the SD of the residuals from the above models (all residuals were pooled together before calculating SD). We assumed $\epsilon\sim N(0,8)$ as a starting point. 

# Functions

```{r}
# Cluster variables according to DIFAcTO pipeline.
# If optimize_corr = T, this will override the manual corr_cutoff. Correlation
# cutoff should be optimized for all assays, but does not need to be run every time.
corr_cluster = function(df,folds = 5,outcome = "y",optimize_corr = T, 
                        rseq = seq(0,1,by = 0.01),corr_cutoff = NULL){
  require(igraph)
  require(caret)
  # Get predictors
  pred = setdiff(colnames(df),outcome)
  # Correlations between predictors
  corr_mat = cor(df[,pred],use = "pairwise.complete.obs")
  # Get pairs
  var_cor = corr_mat*lower.tri(corr_mat)
  # Find best correlation cutoff
  if(optimize_corr){
    rs = rseq
    model_perf = lapply(rs, function(r){
      # Correlation cutoff
      check_cor = which(abs(var_cor) >= r, arr.ind=TRUE)
      # Convert correlated pairs into graph clusters
      graph_cor = graph.data.frame(check_cor, directed = FALSE)
      # Get names
      groups_cor = split(unique(as.vector(check_cor)), clusters(graph_cor)$membership)
      groups = lapply(groups_cor,FUN=function(list_cor){rownames(var_cor)[list_cor]})
      # Find highest correlation within each group
      # Use logistic model estimate instead of correlation
      best_cor = lapply(groups, function(g){
        assocs = lapply(g, function(v){
          form = as.formula(paste0(outcome,"~",v))
          mod = lm(form,df)
          coefs = summary(mod)$coefficients
          return(abs(coefs[2,1]))
        })
        return(g[which.max(assocs)])
      })
      best_cor = as.character(best_cor)
      if(length(best_cor)>0){
        # CV with caret
        set.seed(1017)
        cv = trainControl(method = "cv",number = folds)
        # Model
        form = as.formula(paste0(outcome,"~",paste0(best_cor,collapse = "+")))
        # CV
        mod = train(
          form, data = df,
          method = "lm",
          trControl = cv,
          tuneLength = 25
        )
        return(mod$results$RMSE)
      } else {return(NA)}
    })
    opt_r = rs[which.max(model_perf)]
  } else {opt_r = corr_cutoff}
  # final groups
  # Correlation cutoff
  check_cor = which(abs(var_cor) >= opt_r, arr.ind=TRUE)
  # Convert correlated pairs into graph clusters
  graph_cor = graph.data.frame(check_cor, directed = FALSE)
  # Get names
  groups_cor = split(unique(as.vector(check_cor)), clusters(graph_cor)$membership)
  groups = lapply(groups_cor,FUN=function(list_cor){rownames(var_cor)[list_cor]})
  # Find highest correlation within each group
  best_cor = lapply(groups, function(g){
    assocs = lapply(g, function(v){
      form = as.formula(paste0(outcome,"~",v))
      mod = lm(form,df)
      coefs = summary(mod)$coefficients
      return(abs(coefs[2,1]))
    })
    return(g[which.max(assocs)])
  })
  best_cor = as.character(best_cor)
  # Results
  return(list("best" = best_cor,"r_cutoff" = opt_r))
}
```

```{r}
elasticnet = function(df,folds = 5,outcome = "y",n_alphas = 10,n_lambdas = 100,
                      out = "1se.error"){
  require(ensr)
  X = data.matrix(df[,setdiff(colnames(df),outcome)])
  Y = data.matrix(df[,outcome])
  # Grid search
  list2env(list(X=X,Y=Y,n_alphas=n_alphas,n_lambdas=n_lambdas,folds=folds),.GlobalEnv)
  e = ensr(X,Y,alphas = seq(0, 1, length = n_alphas),nlambda = n_lambdas,
           nfolds = folds,parallel = T)
  # Get lambda and alpha
  res = summary(e)
  min_err = min(res$cvm,na.rm = T)
  se_err = sd(res$cvm,na.rm = T)/sqrt(sum(!is.na(res$cvm)))
  if (out == "min.error"){
    good_mods = which.min(res$cvm)
  } else if (out == "1se.error"){
    good_mods = which(res$cvm <= (min_err + se_err))
  }
  params = data.frame(res[good_mods,])
  params = params[which(params$nzero == min(params$nzero)),]
  params = params[which.min(params$cvm),]
  # Refit models to get selected parameters (the coef() function output for caret is confusing)
  a = params$alpha
  l = params$lambda
  mod = glmnet(y = Y,x = X,alpha = a,lambda = l)
  selected = as.matrix(coef(mod))
  selected = rownames(selected)[selected[,1] != 0]
  selected = selected[selected != "(Intercept)"]
  return(as.numeric(sub("X","",selected)))
}
```

```{r warning=FALSE}
# N is the number of metabolites, and n is the number of samples
# p_con controls likelihood of connected nodes
# sd_mean and sd_sd determine the parameters of the normal distribution that the 
# metabolite standard deviations are drawn from
# mean_mean and mean_sd determine the parameters of the normal distribution that the 
# metabolite means are drawn from
# corr_struct determines whether the correlation matrix is completely random or 
# has a clustered structure
sim_data = function(N = 50, n = 1000,p_con = 0.02,
                    sd_min = 1,sd_max = 500,
                    mean_mean = 1500,mean_sd = 830,
                    err_mean = 0,err_sd = 1,
                    beta_mean = 0.002,beta_sd = 0.04,
                    error_sd = 8,
                    corr_struct = "random",
                    seed = 1017){
  set.seed(seed)
  # Random correlation matrix
  r = randcorr(N)
  # Set some correlations to 0
  net = matrix(sample(0:1, N^2, replace=TRUE, prob=c(1-p_con,p_con)), nc=N)
  r = net*r
  # Make symmetric
  l = lower.tri(r)*r
  u = t(l)
  r = l + u
  diag(r) = 1
  r = data.matrix(r)
  # Correlation matrix to covariance
  sds = runif(N,min = sd_min,max = sd_max)
  # diag(S)%*%R%*%diag(S) is covariance where S is SD vector
  cov = diag(sds) %*% r %*% diag(sds)
  # Means
  mus = round(rnorm(N,mean = mean_mean,sd = mean_sd))
  sim = data.frame(mvrnorm(n,mus,cov)) 
  # Outcome related to 3 correlated metabolite pairs
  met = which(r!=0,arr.ind = T)
  met = met[which(met[,1] != met[,2]),]
  met = met[sample(1:nrow(met),3),]
  met = unique(as.vector(met))
  betas = rnorm(length(met),beta_mean,beta_sd)
  sim$y = apply(sim[,met],1,function(r){
    sum(betas*r) + rnorm(1,0,8)
  })
  return(list("simulated_data" = sim,"true_metabs" = met,"true_betas" = betas))
}
```

```{r}
# Jaccard similarity
jaccard <- function(a, b) {
  intersection = length(intersect(a, b))
  union = length(a) + length(b) - intersection
  return (intersection/union)
}
```

```{r}
# Model comparison
compare = function(simulated_data,core_ratio = 0.5){
  cl = makeForkCluster(core_ratio*detectCores())
  t = parLapply(cl,sims, function(s){
    d = s$simulated_data
    # Difacto
    difacto = corr_cluster(d)
    difacto = as.numeric(sub("X","",difacto$best))
    # ElasticNet
    elastic = elasticnet(d)
    # RMSE
    difacto_mod = lm(as.formula(paste0("y~",paste0("X",difacto,collapse = "+"))),d)
    elastic_mod = lm(as.formula(paste0("y~",paste0("X",elastic,collapse = "+"))),d)
    # Results
    return(list(
      # Agreement
      "elastic_jacc" = jaccard(elastic,s$true_metabs),
      "difacto_jacc" = jaccard(difacto,s$true_metabs),
      # RMSE
      "elastic_rmse" = rmse(elastic_mod),"difacto_rmse" = rmse(difacto_mod)))
  })
  stopCluster(cl)
}
```

example

```{r}
n_sims = 1000
# Simulate multiple datasets
sims = lapply(1:n_sims, function(i){
  t = sim_data(seed = i)
  return(t)
})
```

# Limitations

1. DIFAcTO was designed for continuous outcomes and features, so for the abstract we had to make some minor changes to work with our binary outcome.
2. The DIFAcTO code was difficult to run on anything but the example data, so we wrote custom code to reproduce the pipeline. There may be important differences in our code (clustering algorithm, etc.), but the overall idea is the same.
3. We assume a multivariate normal distribution for our features, and a linear model with no interactions or polynomial trends. 
4. So many parameters! Ours were chosen based on COPD gene, but there is no gold standard for metabolomics data.

# Questions for Laura

1. Are these betas too small?
