---
title: "TEDDY Model Selection"
author: "Tim Vigers & Laura Pyle"
date: "`r format(Sys.time(), '%d %B %Y')`"
format:
  html:
    toc: true
    toc-depth: 5
    toc-float: true
    code-fold: true
    self-contained: true
editor: visual
---

```{r include=FALSE}
library(caret)
# Import data
load("~/Documents/Work/BDC/Howard Davidson/TEDDY data/Data_Clean/all_timepoints.RData")
df$y <- as.factor(df$y)
df$time <- as.factor(df$time)
```

# Model Selection with ElasticNet

Data pre-processing steps were completed using the `caret` R package with default settings for all functions (unless otherwise specified). Pre-processing includes zero-variance filter, near-zero variance filter, correlation filter,centering, and scaling.

Using a missingness cutoff of < 75% results in 140 observations of 1,350 variables going into the ElasticNet step. Increasing this threshold to 80% results in 40 observations of 48,535 variables.

## Time 0

```{r cache=TRUE}
# Just t0
X <- df[df$time == 0, ]
X$id <- NULL
X$time <- NULL
# Remove those with high missingness
missing <- as.numeric(which(lapply(X, function(c) {
  sum(is.na(c)) / length(c)
}) >= 0.8))
if (length(missing) > 0) {
  X <- X[, -missing]
}
# Process
pp_X <- preProcess(X[, -1], outcome = X$y, method = c("center", "scale", "zv", "nzv", "conditionalX", "corr"))
# Transform
X[, 2:ncol(X)] <- predict(pp_X, X[, 2:ncol(X)])
```

```{r}
set.seed(1017)
cv <- trainControl(method = "cv", number = 10)
elnet <- train(
  y ~ .,
  data = na.omit(X),
  method = "glmnet",
  trControl = cv,
  tuneLength = 100
)
elnet
```

# Questions

1. What is going on with the missing data threshold? Is this due to the transcriptomics data and should we exclude that?
