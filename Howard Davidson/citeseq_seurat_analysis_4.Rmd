<<<<<<< HEAD
---
title: ""
author: "Tim Vigers & Laura Pyle"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  html_document:
    number_sections: yes
    toc: yes
    toc_depth: 5
    toc_float: yes
---

```{r setup, include=FALSE}
library(tidyverse)
library(Seurat) # need these for Differential expression testing
library(SeuratObject)
library(data.table)
library(broom)
library(pROC)
library(caTools)
# update the dfs as change (changes in first chunk of version 3 on the Lambda)
perc_express_cluster <- read.csv("S:/Laura/BDC/Projects/Howard Davidson/perc_express_cluster_TEST.csv")

# check donor cluster level
perc_express_donorcluster  <- read.csv("S:/Laura/BDC/Projects/Howard Davidson/perc_express_donorcluster_TEST.csv")
#rownames(df2) = colnames(perc_express_donorcluster)

# data
home_dir = "S:/Laura/BDC/Projects/Howard Davidson/R01/Data_Raw/Davidson pilot data/"
knitr::opts_knit$set(root.dir = home_dir)
#setwd("S:/Laura/BDC/Projects/Howard Davidson/R01/Data_Raw/Davidson pilot data/")
df = readRDS(paste0(home_dir, "OneDrive_1_6-28-2023/normalized.rds"))
df2 = df
```


```{r fun, include = FALSE}
gene_list = function(df, cutoff){
  # df is one cluster w/ all donors at perc_expr level
  dft = as.data.frame(t(df)[-1,])
  donors  = colnames(dft)
  donorgenes = list()
  for(i in donors){
    nam = dft %>% select(i)
    donor_vec = nam %>% filter(.[[1]] > cutoff)  %>% rownames()
    donorgenes[[i]] = donor_vec
  }
  return(donorgenes)
}


# test code for function above
# c_0 = perc_express_donorcluster %>% filter(cluster == 0) %>% select(-cluster)
# # start fn
# c_0_t = as.data.frame(t(c_0)[-1,])
# donor1_0 = c_0_t %>% select(V1) %>% filter(V1 > 20) %>% rownames() %>% c()# ~ 1400 genes at 20% cutoff for d1c0
# genes_1_0 = rownames(donor1_0)
# donor2_0 = c_0_t %>% select(V2) %>% filter(V2 > 20) # ~ 1400 genes at 20% cutoff for d1c0
# genes_2_0 = rownames(donor2_0)
# gene_list_0_test = intersect(genes_1_0, genes_2_0)


# Tims elnet
source("D:/Repositories/shared-resources/Machine Learning/Tim - ElasticNet CV/easy_elasticnet.R")
```
Calculate gene frequencies for each donor in cluster 0 and remove genes that have a freq < X eg 0.2

Add cluster tag to gene name to create unique ID eg B2M  becomes “0-B2M” etc

Bind rows for each donor

Determine number of occurrences for each gene and remove those with values less than 23.

Repeat for other clusters.


Clarify: 

For each Cluster,

get percent expressions by donor to get a list of genes expressing above a minimum % cutoff
remove the genes not expressed by all donors within the cluster (only take the intersection of these gene lists)

```{r col clusters, include = F}
# Cluster 0
c_0 = perc_express_donorcluster %>% filter(cluster == 0) %>% select(-cluster)
a = gene_list(c_0, 22.3) 
cluster0_genes = Reduce(intersect, a) # 22.3 for 505 

# Cluster 1
c_1 = perc_express_donorcluster %>% filter(cluster == 1) %>% select(-cluster)
a = gene_list(c_1, 28) # 28 for 502
cluster1_genes = Reduce(intersect, a)

# Cluster 2
c_2 = perc_express_donorcluster %>% filter(cluster == 2) %>% select(-cluster)
a = gene_list(c_2, 26)
cluster2_genes = Reduce(intersect, a) #26% for 500 exactly hot dog

# Cluster 3
c_3 = perc_express_donorcluster %>% filter(cluster == 3) %>% select(-cluster)
a = gene_list(c_3, 28)
cluster3_genes = Reduce(intersect, a)
# Cluster 4
c_4 = perc_express_donorcluster %>% filter(cluster == 4) %>% select(-cluster)
a = gene_list(c_4, 31.6)
cluster4_genes = Reduce(intersect, a)
# Cluster 5
c_5 = perc_express_donorcluster %>% filter(cluster == 5) %>% select(-cluster)
a = gene_list(c_5, 29.4)
cluster5_genes = Reduce(intersect, a)
# Cluster 6
c_6 = perc_express_donorcluster %>% filter(cluster == 6) %>% select(-cluster)
a = gene_list(c_6, 21)
cluster6_genes = Reduce(intersect, a)
# Cluster 7
c_7 = perc_express_donorcluster %>% filter(cluster == 7) %>% select(-cluster)
a = gene_list(c_7,26)
cluster7_genes = Reduce(intersect, a)
# Cluster 8
c_8 = perc_express_donorcluster %>% filter(cluster == 8) %>% select(-cluster)
a = gene_list(c_8, 26.3)
cluster8_genes = Reduce(intersect, a)
# Cluster 9
c_9 = perc_express_donorcluster %>% filter(cluster == 9) %>% select(-cluster)
a = gene_list(c_9,19.3)
cluster9_genes = Reduce(intersect, a)
# Cluster 10
c_10 = perc_express_donorcluster %>% filter(cluster == 10) %>% select(-cluster)
a = gene_list(c_10,6.5)
cluster10_genes = Reduce(intersect, a)
# Cluster 11
c_11 = perc_express_donorcluster %>% filter(cluster == 11) %>% select(-cluster)
a = gene_list(c_11,0)
cluster11_genes = Reduce(intersect, a) # only 400 shared genes between these
# Cluster 12
c_12 = perc_express_donorcluster %>% filter(cluster == 12) %>% select(-cluster)
a = gene_list(c_12,0)
cluster12_genes = Reduce(intersect, a) # only 275 shared genes between donors

```

```{r previous output}
# outcomes data
read_excel_allsheets <- function(filename, tibble = FALSE) {
    # I prefer straight data.frames
    # but if you like tidyverse tibbles (the default with read_excel)
    # then just pass tibble = TRUE
    sheets <- readxl::excel_sheets(filename)
    x <- lapply(sheets, function(X) readxl::read_excel(filename, sheet = X))
    if(!tibble) x <- lapply(x, as.data.frame)
    names(x) <- sheets
    x
}


a1ccpep = read_excel_allsheets("S:/Laura/BDC/Projects/Howard Davidson/R01/Data_Raw/Davidson pilot data/IDDA1C_Cpep.xlsx")
# remove all df as it looks incomplete
a1ccpep = a1ccpep[-1]

# change to numeric
a1c_df <- Reduce(function(x, y) merge(x, y, all = TRUE), a1ccpep)
a1c_df = a1c_df %>% filter(!is.na(`HWD ID`)) %>% mutate(a1c = as.numeric( case_when(A1c_Value == "NULL" ~ NA,
                                                                        TRUE ~ A1c_Value))) ; rm(a1ccpep)
# add in outcome vars
a1c_df = a1c_df %>% arrange(`HWD ID`, as.Date(VisitDate)) %>% group_by(`HWD ID`) %>% mutate(visit = row_number(),
                                                                                            a1c_g7 = ifelse(a1c > 7, "G7","L7")) # visit num
a1c_df = data.table(a1c_df, key = '`HWD ID`')
a1c_df = a1c_df[, days_from_v1 :=  cumsum(c(0, diff(as.Date(VisitDate)))), by=`HWD ID`]# days from baseline
a1c_df = a1c_df %>% mutate(y1_elig = ifelse(abs(days_from_v1- 365) < 90, 1, 0),
                           abs_y1_days = ifelse(abs(days_from_v1- 365) < 90, abs(days_from_v1- 365), NA))

a1c_y1 = a1c_df %>% group_by(`HWD ID`) %>% summarise(min_y1_days = min(abs_y1_days, na.rm = T))
a1c_y1 = a1c_df %>% group_by(`HWD ID`) %>% summarise(min_y1_days = min(abs_y1_days, na.rm = T))
a1c_y1$min_y1_days[is.infinite(a1c_y1$min_y1_days)] = NA
a1c_df = full_join(a1c_df, a1c_y1); rm(a1c_y1)
a1c_df = a1c_df %>% mutate(yr1a1c = ifelse(abs_y1_days == min_y1_days, a1c, NA))
a1c_df = a1c_df %>% group_by(`HWD ID`) %>% fill(yr1a1c)


avg_a1c = a1c_df %>% group_by(`HWD ID`) %>% summarise(meana1c = mean(a1c, na.rm = T),
                                                      firsta1c = first(a1c, na_rm = T),
                                                      maxa1c = max(a1c, na.rm=T),
                                                      yr1a1c = mean(yr1a1c, na.rm = T)) %>% mutate(id = `HWD ID`)
# add in slopes and auc
a1c_slopes = a1c_df %>% group_by(`HWD ID`) %>% do(tidy(lm(a1c ~ days_from_v1, data = .))) %>% filter(term == "days_from_v1") %>% select(`HWD ID`, estimate) %>% rename(a1c_slope = estimate)
avg_a1c = left_join(avg_a1c, a1c_slopes) ; rm(a1c_slopes)

avg_a1c$a1c_auc = sapply(split(a1c_df,a1c_df$`HWD ID`),function(df) trapz(df$days_from_v1,df$a1c))

# dichotomize
avg_a1c = avg_a1c %>% mutate(avg_a1c_g_med = ifelse(meana1c > median(meana1c,na.rm = T), "G_med", " L_med"),
                             first_a1c_g_med = ifelse(firsta1c > median(firsta1c,na.rm = T), "G_med", " L_med"),
                             y1_a1c_g_med = ifelse(yr1a1c > median(yr1a1c,na.rm = T), "G_med", " L_med"),
                             max_a1c_g_med = ifelse(maxa1c > median(maxa1c,na.rm = T), "G_med", " L_med"),
                             slope_a1c_g_med = ifelse(a1c_slope > median(a1c_slope,na.rm = T), "G_med", " L_med"),
                             auc_a1c_g_med = ifelse(a1c_auc > median(a1c_auc,na.rm = T), "G_med", " L_med"))


df2@meta.data = left_join(df2@meta.data, avg_a1c,  by=c('donor_number'='id'))
# View(df2@meta.data)

# add in other outcomes
# IDDA1c
avg_idda1c = a1c_df %>% group_by(`HWD ID`) %>% summarise(mean_idda1c = mean(IDDA1C, na.rm = T)) %>% mutate(id = `HWD ID`)
# add in slopes and auc
idda1c_slopes = a1c_df %>% group_by(`HWD ID`) %>% do(tidy(lm(IDDA1C ~ days_from_v1, data = .))) %>% filter(term == "days_from_v1") %>% 
  select(`HWD ID`, estimate) %>% rename(idda1c_slope = estimate)
avg_idda1c = left_join(avg_idda1c, idda1c_slopes) ; rm(idda1c_slopes)

avg_idda1c$idda1c_auc = sapply(split(a1c_df,a1c_df$`HWD ID`),function(df) trapz(df$days_from_v1,df$IDDA1C))

# dichotomize
avg_idda1c = avg_idda1c %>% mutate(avg_idda1c_g_med = ifelse(mean_idda1c > median(mean_idda1c,na.rm = T), "G_med", " L_med"),
                             slope_idda1c_g_med = ifelse(idda1c_slope > median(idda1c_slope,na.rm = T), "G_med", " L_med"),
                             auc_idda1c_g_med = ifelse(idda1c_auc > median(idda1c_auc,na.rm = T), "G_med", " L_med"))

df2@meta.data = left_join(df2@meta.data, avg_idda1c,  by=c('donor_number'='id'))


# total daily insulin dose
a1c_df$dose_udk = a1c_df$`U/day/kg`
avg_dose_udk = a1c_df %>% group_by(`HWD ID`) %>% summarise(mean_dose_udk = mean(dose_udk, na.rm = T)) %>% mutate(id = `HWD ID`)
# add in slopes and auc
dose_udk_slopes = a1c_df %>% group_by(`HWD ID`) %>% do(tidy(lm(dose_udk ~ days_from_v1, data = .))) %>% filter(term == "days_from_v1") %>% 
  select(`HWD ID`, estimate) %>% rename(dose_udk_slope = estimate)
avg_dose_udk = left_join(avg_dose_udk, dose_udk_slopes) ; rm(dose_udk_slopes)

avg_dose_udk$dose_udk_auc = sapply(split(a1c_df,a1c_df$`HWD ID`),function(df) trapz(df$days_from_v1,df$dose_udk))

# dichotomize
avg_dose_udk = avg_dose_udk %>% mutate(avg_dose_udk_g_med = ifelse(mean_dose_udk > median(mean_dose_udk,na.rm = T), "G_med", " L_med"),
                             slope_dose_udk_g_med = ifelse(dose_udk_slope > median(dose_udk_slope,na.rm = T), "G_med", " L_med"),
                             auc_dose_udk_g_med = ifelse(dose_udk_auc > median(dose_udk_auc,na.rm = T), "G_med", " L_med"))

df2@meta.data = left_join(df2@meta.data, avg_dose_udk,  by=c('donor_number'='id'))

# cpep
a1c_df = a1c_df %>% mutate(est_cpep = ifelse(`Est C-pep` > 0, `Est C-pep`, 0))
avg_est_cpep = a1c_df %>% group_by(`HWD ID`) %>% summarise(mean_est_cpep = mean(est_cpep, na.rm = T)) %>% mutate(id = `HWD ID`)
# add in slopes and auc
est_cpep_slopes = a1c_df %>% group_by(`HWD ID`) %>% do(tidy(lm(est_cpep ~ days_from_v1, data = .))) %>% filter(term == "days_from_v1") %>% 
  select(`HWD ID`, estimate) %>% rename(est_cpep_slope = estimate)
avg_est_cpep = left_join(avg_est_cpep, est_cpep_slopes) ; rm(est_cpep_slopes)

avg_est_cpep$est_cpep_auc = sapply(split(a1c_df,a1c_df$`HWD ID`),function(df) trapz(df$days_from_v1,df$est_cpep))

# dichotomize
avg_est_cpep = avg_est_cpep %>% mutate(avg_est_cpep_g_med = ifelse(mean_est_cpep > median(mean_est_cpep,na.rm = T), "G_med", " L_med"),
                             slope_est_cpep_g_med = ifelse(est_cpep_slope > median(est_cpep_slope,na.rm = T), "G_med", " L_med"),
                             auc_est_cpep_g_med = ifelse(est_cpep_auc > median(est_cpep_auc,na.rm = T), "G_med", " L_med"))

df2@meta.data = left_join(df2@meta.data, avg_est_cpep,  by=c('donor_number'='id'))
test = df2@meta.data
```
QUESTIONS:

- Understanding of avg by donor cells then by cluster; is this still in percent expressed, or have we gone into mean express territory?
-- for percent expressed when aggregated first into donor-cluster cells then back into cluster over a quarter have 100% expressed for c0;
--------for AL627309 (first col in un transposed donor-cluster ) in  we have 11/23 subjects in cluster 0 with very small % express -- into the cluster form we have 47.8% is this the correct % we are looking for?


UPDATE: next steps similar to difacto study (emailed from kristen);
1) identify features corr w outcome -- delta, auc (coded in previous citeseq seurat analysis)
-- average by donor cells then by cluster (intersect the cluster with the donors cells -- 20% or x% perc expression)

2) elasticnet


```{r test elnet, include = FALSE}
# donor and hwd id match
ids = df2@meta.data %>% select(donor, `HWD ID.y`) %>% unique()
colnames(ids) = c("donor", "HWD ID")
avg_a1c = full_join(avg_a1c, ids)

# cluster 0
c_0$donor = factor(c_0$donor)
analysis_0 = full_join(avg_a1c, c_0)
analysis_0 = analysis_0 %>%  filter(!is.na(donor)) %>% select(a1c_slope, cluster0_genes)
# not converging for our 500 so well choose the most correlated 100 to a1c slope
test_cor_0 = as.data.frame(cor(analysis_0,analysis_0$a1c_slope))
test_cor_0$gene = rownames(test_cor_0)
test_cor_0$V1 = abs(test_cor_0$V1)
test_cor_0 = test_cor_0[order(test_cor_0$V1, decreasing = T),]
cluster0_genes_test = test_cor_0$gene[2:71]
cluster0_genes_test  = make.names(cluster0_genes_test , unique = T, allow_ = F)


cluster0_en = easy_elasticnet(data = analysis_0, outcome = "a1c_slope",cv_method = "loo",
                              predictors = cluster0_genes_test, model_type = "gaussian")

print(cluster0_en)

# cluster 1
c_1$donor = factor(c_1$donor)
analysis_1 = full_join(avg_a1c, c_1)
analysis_1 = analysis_1 %>%  filter(!is.na(donor)) %>% select(a1c_slope, cluster1_genes)
# not converging for our 500 so well choose the most correlated 100 to a1c slope
test_cor_1 = as.data.frame(cor(analysis_1,analysis_1$a1c_slope))
test_cor_1$gene = rownames(test_cor_1)
test_cor_1$V1 = abs(test_cor_1$V1)
test_cor_1 = test_cor_1[order(test_cor_1$V1, decreasing = T),]
cluster1_genes_test = test_cor_1$gene[2:51]
cluster1_genes_test  = make.names(cluster1_genes_test , unique = T, allow_ = F)


cluster1_en = easy_elasticnet(data = analysis_1, outcome = "a1c_slope",cv_method = "loo",
                              predictors = cluster1_genes_test, model_type = "gaussian")

print(cluster1_en)


# cluster 1
c_2$donor = factor(c_2$donor)
analysis_2 = full_join(avg_a1c, c_2)
analysis_2 = analysis_2 %>%  filter(!is.na(donor)) %>% select(a1c_slope, cluster2_genes)
# not converging for our 500 so well choose the most correlated 100 to a1c slope
test_cor_2 = as.data.frame(cor(analysis_2,analysis_2$a1c_slope))
test_cor_2$gene = rownames(test_cor_2)
test_cor_2$V1 = abs(test_cor_2$V1)
test_cor_2 = test_cor_2[order(test_cor_2$V1, decreasing = T),]
cluster2_genes_test = test_cor_2$gene
cluster2_genes_test  = make.names(cluster2_genes_test , unique = T, allow_ = F)


cluster2_en = easy_elasticnet(data = analysis_2, outcome = "a1c_slope",cv_method = "loo",
                              predictors = cluster2_genes_test, model_type = "gaussian")

print(cluster2_en)
```
to do: rank genes by corr to outcome and choose n (50-100 maybe) highest corrs


2) elasticnet

## Change in CAC per year

```{r include=FALSE}

# omics selected by moderated t-test and PLSDA
omics = unique(c("gly_P02671.7","gly_P02671.5","gly_P02671.4","gly_P02671.3",
          "AAA01201000179.0807263.4","gly_P02679","HMDB00510161.0696402.9",
          "AAA01201000179.0809235.7","gly_P02675.4","gly_P02675","gly_P02647",
          "P02655","gly_P02647.1","HMDB00510161.0694436","gly_P02652",
          "gly_P01009","gly_P01834.11","P01817","AcCa 10:3",
          "HMDB0028822260.1378628.6","AAA01201000179.0807263.4",
          "gly_P02671.3","gly_P02671.7"))
limited_omics = c("AAA01201000179.0807263.4","gly.P02671.7","gly.P02671.3",
          "gly.P02671.5","gly.P02671.4")
# Take out people without diabetes, remove diabetes status from predictors
df = df[df$diabetic == 1,]
clinical_predictors = clinical_predictors[-which(clinical_predictors == "dia")]
# Log transform 
df[,omics] = log(df[,omics])
# Fix names
colnames(df)[which(colnames(df) %in% omics)] = make.names(omics,unique = T,allow_ = F)
omics = make.names(omics,unique = T,allow_ = F)
# Variables for null model
null_vars <- c("age","sex","durcatV1")
# Sometimes using too many alpha/lambda values results in duplicate values for the 
# error metric. This doesn't seem to be a problem but throws a lot of warnings
cac_change_select = easy_elasticnet(data = df,outcome = "cac_change_per_yr",
                           predictors = clinical_predictors,
                           model_type = "gaussian")
```

### Null model (age, sex, T1D duration only)

```{r}
n_cac_change  = as.formula(paste0("cac_change_per_yr~",paste0(null_vars,collapse = "+")))
null_mod = lm(formula = n_cac_change,data = df)
kable(tidy(null_mod),digits = 3)
```

### Clinical model results

```{r}
f_cac_change = as.formula(paste0("cac_change_per_yr~",
                                 paste0(cac_change_select,collapse = "+")))
clin_mod = lm(formula = f_cac_change,data = df)
kable(tidy(clin_mod),digits = 3)
```

### Omics model results (no imputation)

```{r}
omics_mod = lm(formula = update(f_cac_change,paste0("~ . +",paste0(limited_omics,collapse = "+"))),
         data = df)
kable(tidy(omics_mod),digits = 3)
```

### Model comparison

```{r}
mc = as.data.frame(compare_performance(clin_mod,omics_mod,null_mod,
                                       metrics = c("R2","R2_adj"),verbose = F))
mc$Name = c("Clinical Model","Omics Model","Null model")
kable(mc,digits = 3)
```
