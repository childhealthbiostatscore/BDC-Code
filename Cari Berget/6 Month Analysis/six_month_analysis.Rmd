---
title: "6 Month Analysis"
author: "Tim Vigers & Laura Pyle"
date: "`r format(Sys.time(), '%d %B %Y')`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tools)
library(tableone)
library(nlme)
library(knitr)
library(reshape2)
library(tidyverse)
source("/Users/timvigers/Documents/GitHub/Tim-and-Laura/tim_R_functions.R")
# Check OS and alter file path accordingly.
if (.Platform$OS.type == "windows") {pathstart <- "//ucdenver.pvt/"} else if (.Platform$OS.type == "unix"){pathstart <- "/Volumes/"}
```

```{r echo=FALSE,warning=FALSE,eval=FALSE}
# Read in glycemic data
filename <- paste0(pathstart,"som/PEDS/RI Biostatistics Core/Shared/Shared Projects/Laura/BDC/Projects/Cari Berget/6 Month Manuscript/Data_Cleaned/670GChild_GlycemicDATA_2019-01-07_.csv")
glycemicdata <- read.csv(filename,na.strings = "",stringsAsFactors = F)
# Format dates
datecols <- c("demographics_consent","demographics_dob","demographics_diabetesdx","automode_start",
              "hba1c_date_b","hba1c_date_m1","t1_date_m1","hba1c_date_t1","t1_date","hba1c_date_t2",
              "t2_date")
glycemicdata[,datecols] <- lapply(glycemicdata[,datecols], function(x) mdy(x,tz = "MST"))
```

```{r echo=FALSE, eval=FALSE}
# Re-assign visit dates based on Cari's decisions. CSV file manually edited for easier import.
# Notes:
# 1. Cari is double checking #14 dates, others in CSV file are correct. 
# 2. Baseline A1c can be 2 weeks after AM start.
# 3. "Date Questions.csv" manually edited for easier R import.
filename <- paste0(pathstart,"som/PEDS/RI Biostatistics Core/Shared/Shared Projects/Laura/BDC/Projects/Cari Berget/6 Month Manuscript/Data_Cleaned/Date Questions.csv")
correct.dates <- read.csv(filename,stringsAsFactors = F,na.strings = c("","none"))
correct.dates[,2:5] <- lapply(correct.dates[,2:5],function(x) mdy(x,tz = "MST"))
# Split into separate data frames, rename columns.
m1cols <- c(grep("m1_",colnames(glycemicdata)),grep("_m1",colnames(glycemicdata)))
original.m1 <- glycemicdata[,c(1,m1cols)]
colnames(original.m1) <- sub("_m1","",colnames(original.m1))
colnames(original.m1) <- sub("t1_","",colnames(original.m1))
# T1
t1cols <- c(grep("t1_",colnames(glycemicdata)),grep("_t1",colnames(glycemicdata)))
original.t1 <- glycemicdata[,c(1,t1cols)]
colnames(original.t1) <- sub("t1_","",colnames(original.t1))
colnames(original.t1) <- sub("_t1","",colnames(original.t1))
# T2
t2cols <- c(grep("t2_",colnames(glycemicdata)),grep("_t2",colnames(glycemicdata)))
original.t2 <- glycemicdata[,c(1,t2cols)]
colnames(original.t2) <- sub("t2_","",colnames(original.t2))
colnames(original.t2) <- sub("_t2","",colnames(original.t2))
# Define variables of interest
vars <- c("hba1c","am_time","mm_time","sensor_wear","sensor_u54","sensor_55_69",
          "sensor_70_180","sensor_181_250","sensor_g250","mean_sg","sd",
          "bg_checks","calibrations","tdd","basal","bolus","amexit",
          "amexit_day","amexit_hyper","amexit_hypo","amexit_manual","amexit_other")
# Combine, remove duplicates and melt
allcols <- c("record_id","date",vars)
alldat <- rbind(original.m1[,allcols],original.t1[,allcols],original.t2[,allcols])
alldat <- alldat[which(duplicated(alldat[,c("record_id","date")])==F),]
alldat <- melt(alldat,id.vars = c("record_id","date"))
# Spread
alldat <- spread(alldat,key = variable,value = value)
# Get corrected M1 data
m1 <- correct.dates[,c("record_id","correct.m1.date")]
colnames(m1) <- c("record_id","date")
m1 <- left_join(m1,alldat,by = c("record_id","date"))
m1$tpoint <- "M1"
# Get corrected T1 data
t1 <- correct.dates[,c("record_id","correct.t1.date")]
colnames(t1) <- c("record_id","date")
t1 <- left_join(t1,alldat,by = c("record_id","date"))
t1$tpoint <- "T1"
# Get corrected T2 data
t2 <- correct.dates[,c("record_id","correct.t2.date")]
colnames(t2) <- c("record_id","date")
t2 <- left_join(t2,alldat,by = c("record_id","date"))
t2$tpoint <- "T2"
# Merge M1, T1, and T2
alldat <- bind_rows(m1,t1,t2)
alldat <- alldat[order(alldat$record_id),]
# Add autmode start and calculate days
alldat <- merge(alldat,glycemicdata[,c("record_id","automode_start")])
alldat$days <- as.numeric(difftime(alldat$date, alldat$automode_start,units = "days"))
# Import baseline data
filename <- paste0(pathstart,"som/PEDS/RI Biostatistics Core/Shared/Shared Projects/Laura/BDC/Projects/Cari Berget/6 Month Manuscript/Data_Cleaned/670GChild_BaselineGlycemicData_14JAN2019.csv")
baseline <- read.csv(filename)
colnames(baseline) <- sub("_b","",colnames(baseline))
baseline$tpoint <- "B"
# Merge everything, sort
alldat <- bind_rows(alldat,baseline)
alldat <- alldat[order(alldat$record_id),]
# Make record ID and timepoint factor
alldat$record_id <- as.factor(alldat$record_id)
alldat$tpoint <- as.factor(alldat$tpoint)
# Get baseline A1c
alldat$hba1c[alldat$tpoint == "B"] <- glycemicdata$hba1c_baseline
# Notes

# List of manual data changes
# Renames columns:
# sensor_54_69_m1 to sensor_55_69_m1
# baseline data sensor_54_69 to sensor_55_69
# all "amexits" to "amexit"

# Additional data notes
# Using a strict 3 month +/- 45 days window would have resulted in the loss of quite a bit of data, so visit dates were manually re-classified by Cari Berget. 
# The cleaned data was sent to Cari Berget due to several concerning outliers. She corrected the data and sent it back, so this chunk of code no longer needs to run. The cleaned data from Cari is just imported instead.  
```

```{r echo=FALSE,eval=FALSE}
# Read in survey data
filename <- paste0(pathstart,"som/PEDS/RI Biostatistics Core/Shared/Shared Projects/Laura/BDC/Projects/Cari Berget/6 Month Manuscript/Data_Cleaned/670GChildSurvey_DATA_2019-01-07_.csv")
child <- read.csv(filename,na.strings = "",stringsAsFactors = F)
# Column names for each survey
b_cols_paid <- paste0("c_paid",seq(1:20))
t1_cols_paid <- paste0(b_cols_paid,"_t1")
t2_cols_paid <- paste0(b_cols_paid,"_t2")
b_cols_maintain <- paste0("c_hfs_behave",c(3,4,7))
t1_cols_maintain <- paste0(b_cols_maintain,"_t1")
t2_cols_maintain <- paste0(b_cols_maintain,"_t2")
b_cols_helpless <- paste0("c_hfs_worry",c(11,12,13,14,16,18,19,22,23))
t1_cols_helpless <- paste0(b_cols_helpless,"_t1")
t2_cols_helpless <- paste0(b_cols_helpless,"_t2")
b_cols_worry <- paste0("c_hfs_worry",c(15,17,20,21,25))
t1_cols_worry <- paste0(b_cols_worry,"_t1")
t2_cols_worry <- paste0(b_cols_worry,"_t2")
# Score by timepoint, gather into separate frame
child$B <- apply(child[,b_cols_paid],1,function(x) mean((4 - (x - 1)),na.rm = T) * 25)
child$T1 <- apply(child[,t1_cols_paid],1,function(x) mean((4 - (x - 1)),na.rm = T) * 25)
child$T2 <- apply(child[,t2_cols_paid],1,function(x) mean((4 - (x - 1)),na.rm = T) * 25)
paid <- gather(child[,c("record_id","B","T1","T2")],tpoint, paid_score, B:T2)

child$B <- apply(child[,b_cols_maintain],1,function(x) sum((x - 1)))
child$T1 <- apply(child[,t1_cols_maintain],1,function(x) sum((x - 1)))
child$T2 <- apply(child[,t2_cols_maintain],1,function(x) sum((x - 1)))
maintain <- gather(child[,c("record_id","B","T1","T2")],tpoint, maintain_score, B:T2)

child$B <- apply(child[,b_cols_helpless],1,function(x) sum((x - 1)))
child$T1 <- apply(child[,t1_cols_helpless],1,function(x) sum((x - 1)))
child$T2 <- apply(child[,t2_cols_helpless],1,function(x) sum((x - 1)))
helpless <- gather(child[,c("record_id","B","T1","T2")],tpoint, helpless_score, B:T2)

child$B <- apply(child[,b_cols_worry],1,function(x) sum((x - 1)))
child$T1 <- apply(child[,t1_cols_worry],1,function(x) sum((x - 1)))
child$T2 <- apply(child[,t2_cols_worry],1,function(x) sum((x - 1)))
worry <- gather(child[,c("record_id","B","T1","T2")],tpoint, worry_score, B:T2)
# Gather, merge, and order all surveys, replace NaN with NA, rename columns.
child_surveys <- plyr::join_all(list(paid,maintain,helpless,worry), by = c("record_id","tpoint"))
child_surveys <- child_surveys[order(child_surveys$record_id),]
child_surveys$paid_score[is.nan(child_surveys$paid_score)] <- NA
colnames(child_surveys) <- c("record_id","tpoint","cpaid_score","cmaintain_score","chelpless_score","cworry_score")
# Write CSV
filename <- paste0(pathstart,"som/PEDS/RI Biostatistics Core/Shared/Shared Projects/Laura/BDC/Projects/Cari Berget/6 Month Manuscript/Data_Cleaned/clean_child_survey.csv")
write.csv(child_surveys,file = filename,row.names = F,na = "")
```

```{r echo=FALSE,eval=FALSE}
# YA survey scores
filename <- paste0(pathstart,"som/PEDS/RI Biostatistics Core/Shared/Shared Projects/Laura/BDC/Projects/Cari Berget/6 Month Manuscript/Data_Cleaned/670GYoungAdult_SurveyDATA_2019-01-07_.csv")
ya <- read.csv(filename,na.strings = "",stringsAsFactors = F)
# Change column names
b_cols_paid <- paste0("ya_paid",seq(1:20),"_base")
t1_cols_paid <- paste0("ya_paid",seq(1:20),"_t1")
t2_cols_paid <- paste0("ya_paid",seq(1:20),"_t2")
b_cols_behavior <- paste0("ya_hfs_behave",1:15,"_b")
t1_cols_behavior <- paste0("ya_hfs_behave",1:15,"_t1")
# Note: manually changed column "ya_hfs_behave9_b_t1_t2" to "ya_hfs_behave9_t2"
t2_cols_behavior <- paste0("ya_hfs_behave",1:15,"_t2")
b_cols_worry <- paste0("ya_hfs_worry",1:18,"_b")
t1_cols_worry <- paste0("ya_hfs_worry",1:18,"_t1")
t2_cols_worry <- paste0("ya_hfs_worry",1:18,"_t2")
# Score by timepoint, gather into separate frame
ya$B <- apply(ya[,b_cols_paid],1,function(x) sum(x) * 1.25)
ya$T1 <- apply(ya[,t1_cols_paid],1,function(x) sum(x) * 1.25)
ya$T2 <- apply(ya[,t2_cols_paid],1,function(x) sum(x) * 1.25)
paid <- gather(ya[,c("record_id","B","T1","T2")],tpoint, paid_score, B:T2)

ya$B <- apply(ya[,b_cols_behavior],1,function(x) sum((x - 1),na.rm = T))
ya$T1 <- apply(ya[,t1_cols_behavior],1,function(x) sum((x - 1),na.rm = T))
ya$T2 <- apply(ya[,t2_cols_behavior],1,function(x) sum((x - 1),na.rm = T))
behavior <- gather(ya[,c("record_id","B","T1","T2")],tpoint, behavior_score, B:T2)

ya$B <- apply(ya[,b_cols_worry],1,function(x) sum((x - 1),na.rm = T))
# Note: manually changed column "ya_hfs_worry8_b_t1" to "ya_hfs_worry8_t1"
ya$T1 <- apply(ya[,t1_cols_worry],1,function(x) sum((x - 1),na.rm = T))
ya$T2 <- apply(ya[,t2_cols_worry],1,function(x) sum((x - 1),na.rm = T))
worry <- gather(ya[,c("record_id","B","T1","T2")],tpoint, worry_score, B:T2)
# Gather, merge, and order all surveys. Calculate total HFS. Rename columns.
ya_surveys <- plyr::join_all(list(paid,behavior,worry), by = c("record_id","tpoint"))
ya_surveys <- ya_surveys[order(ya_surveys$record_id),]
ya_surveys$total_hfs <- ya_surveys$behavior_score + ya_surveys$worry_score
colnames(ya_surveys) <- c("record_id","tpoint","yapaid_score","yabehavior_score","yaworry_score","yatotal_score")
# Write CSV
filename <- paste0(pathstart,"som/PEDS/RI Biostatistics Core/Shared/Shared Projects/Laura/BDC/Projects/Cari Berget/6 Month Manuscript/Data_Cleaned/clean_ya_survey.csv")
write.csv(ya_surveys,file = filename,row.names = F,na = "")
```

```{r echo=FALSE,eval=FALSE}
# Parent survey scores
filename <- paste0(pathstart,"som/PEDS/RI Biostatistics Core/Shared/Shared Projects/Laura/BDC/Projects/Cari Berget/6 Month Manuscript/Data_Cleaned/670GParentSurvey_DATA_2019-01-07_.csv")
parent <- read.csv(filename,na.strings = "",stringsAsFactors = F)
# Column names for each survey
b_cols_paid <- paste0("p_paid",seq(1:18))
t1_cols_paid <- paste0(b_cols_paid,"_t1")
t2_cols_paid <- paste0(b_cols_paid,"_t2")
b_cols_maintain <- paste0("p_hfs_behave",c(3,4,7))
t1_cols_maintain <- paste0(b_cols_maintain,"_t1")
t2_cols_maintain <- paste0(b_cols_maintain,"_t2")
b_cols_helpless <- paste0("p_hfs_worry",c(12,13,14,15,17,20,23,24,25,26))
t1_cols_helpless <- paste0(b_cols_helpless,"_t1")
t2_cols_helpless <- paste0(b_cols_helpless,"_t2")
b_cols_worry <- paste0("p_hfs_worry",c(16,18,19,21,22))
t1_cols_worry <- paste0(b_cols_worry,"_t1")
t2_cols_worry <- paste0(b_cols_worry,"_t2")
# Score by timepoint, gather into separate frame
parent$B <- apply(parent[,b_cols_paid],1,function(x) mean((4 - (x - 1)),na.rm = T) * 25)
parent$T1 <- apply(parent[,t1_cols_paid],1,function(x) mean((4 - (x - 1)),na.rm = T) * 25)
parent$T2 <- apply(parent[,t2_cols_paid],1,function(x) mean((4 - (x - 1)),na.rm = T) * 25)
paid <- gather(parent[,c("record_id","B","T1","T2")],tpoint, paid_score, B:T2)

parent$B <- apply(parent[,b_cols_maintain],1,function(x) sum((x - 1)))
parent$T1 <- apply(parent[,t1_cols_maintain],1,function(x) sum((x - 1)))
parent$T2 <- apply(parent[,t2_cols_maintain],1,function(x) sum((x - 1)))
maintain <- gather(parent[,c("record_id","B","T1","T2")],tpoint, maintain_score, B:T2)

parent$B <- apply(parent[,b_cols_helpless],1,function(x) sum((x - 1)))
parent$T1 <- apply(parent[,t1_cols_helpless],1,function(x) sum((x - 1)))
parent$T2 <- apply(parent[,t2_cols_helpless],1,function(x) sum((x - 1)))
helpless <- gather(parent[,c("record_id","B","T1","T2")],tpoint, helpless_score, B:T2)

parent$B <- apply(parent[,b_cols_worry],1,function(x) sum((x - 1)))
parent$T1 <- apply(parent[,t1_cols_worry],1,function(x) sum((x - 1)))
parent$T2 <- apply(parent[,t2_cols_worry],1,function(x) sum((x - 1)))
worry <- gather(parent[,c("record_id","B","T1","T2")],tpoint, worry_score, B:T2)
# Gather, merge, and order all surveys, replace NaN with NA. Rename columns.
parent_surveys <- plyr::join_all(list(paid,maintain,helpless,worry), by = c("record_id","tpoint"))
parent_surveys <- parent_surveys[order(parent_surveys$record_id),]
parent_surveys$paid_score[is.nan(parent_surveys$paid_score)] <- NA
colnames(parent_surveys) <- c("record_id","tpoint","ppaid_score","pmaintain_score","phelpless_score","pworry_score")
# Write CSV
filename <- paste0(pathstart,"som/PEDS/RI Biostatistics Core/Shared/Shared Projects/Laura/BDC/Projects/Cari Berget/6 Month Manuscript/Data_Cleaned/clean_parent_survey.csv")
write.csv(parent_surveys,file = filename,row.names = F,na = "")
```

# Methods

Linear mixed effects models were used to examine change in HbA1c over time. Three models were compared using Aikaikeâ€™s Information Criterion to select the best model:

1.	A random intercept model with visit number (baseline, T1, T2) as a categorical time variable.  No adjustment for the baseline value of HbA1c or baseline PAID score.
2.	A random intercept model with visit number as a continuous time variable, without adjustment for baseline.
3.	A random intercept and random slope model, without adjustment for baseline.

The random intercept model with time treated as a categorical variable was the best model. Originally the models were adjusted for baseline value (as we did for the abstract), but it was decided that this adjustment does not make sense given the question this study wants to answer, in addition to making the model results difficult to interpret.

Discontinuation was defined as AM time < 10 at either the 3 month or 6 month visit. Figure 1 and table 2 were generated using data from only those who continued 670G use. 

# Results

```{r echo=FALSE}
# Import Cari's cleaned data
filename <- paste0(pathstart,"som/PEDS/RI Biostatistics Core/Shared/Shared Projects/Laura/BDC/Projects/Cari Berget/6 Month Manuscript/Data_Cleaned/clean_glycemic_data.csv")
alldata <- read.csv(filename,na.strings = "",stringsAsFactors = F,colClasses = c("record_id"="character"))
# Define variables of interest.
vars <- c("hba1c","am_time","mm_time","sensor_wear","sensor_u54","sensor_55_69",
          "sensor_70_180","sensor_181_250","sensor_g250","mean_sg","sd",
          "bg_checks","calibrations","tdd","basal","bolus","amexit",
          "amexit_day","amexit_hyper","amexit_hypo","amexit_manual","amexit_other")
# Import cleaned, scored survey data.
filename <- paste0(pathstart,"som/PEDS/RI Biostatistics Core/Shared/Shared Projects/Laura/BDC/Projects/Cari Berget/6 Month Manuscript/Data_Cleaned/clean_parent_survey.csv")
parent_survey <- read.csv(filename,na.strings = "",stringsAsFactors = F)
filename <- paste0(pathstart,"som/PEDS/RI Biostatistics Core/Shared/Shared Projects/Laura/BDC/Projects/Cari Berget/6 Month Manuscript/Data_Cleaned/clean_child_survey.csv")
child_survey <- read.csv(filename,na.strings = "",stringsAsFactors = F,colClasses = c("record_id"="character"))
filename <- paste0(pathstart,"som/PEDS/RI Biostatistics Core/Shared/Shared Projects/Laura/BDC/Projects/Cari Berget/6 Month Manuscript/Data_Cleaned/clean_ya_survey.csv")
ya_survey <- read.csv(filename,na.strings = "",stringsAsFactors = F,colClasses = c("record_id"="character"))
# Add survey scores to full data.
alldata <- left_join(alldata,child_survey,by = c("record_id","tpoint"))
alldata <- left_join(alldata,ya_survey,by = c("record_id","tpoint"))
alldata <- full_join(alldata,parent_survey,by = c("record_id","tpoint"))
# Order, add baseline A1c, remove AM time < 10% (at T1 or T2)
alldata <- alldata %>%
  arrange(record_id,tpoint) %>%
  group_by(record_id) %>%
  mutate(baseline_a1c = hba1c[1]) %>%
  mutate(baseline_cpaid = cpaid_score[1]) %>%
  mutate(baseline_cmaintain = cmaintain_score[1]) %>%
  mutate(baseline_chelpless = chelpless_score[1]) %>%
  mutate(baseline_cworry = cworry_score[1]) %>%
  mutate(baseline_yapaid = yapaid_score[1]) %>%
  mutate(baseline_yabehavior = yabehavior_score[1]) %>%
  mutate(baseline_yaworry = yaworry_score[1]) %>%
  mutate(baseline_yatotal = yatotal_score[1]) %>%
  mutate(baseline_ppaid = ppaid_score[1]) %>%
  mutate(baseline_pmaintain = pmaintain_score[1]) %>%
  mutate(baseline_phelpless = phelpless_score[1]) %>%
  mutate(baseline_pworry = pworry_score[1])
alldata$tpoint <- as.factor(alldata$tpoint)
alldata$record_id <- as.factor(alldata$record_id)
# Discontinuers
t1_discont <- unique(as.character(alldata$record_id[which(alldata$tpoint == "T1" & alldata$am_time < 10)]))
t2_discont <- unique(as.character(alldata$record_id[which(alldata$tpoint == "T2" & alldata$am_time < 10)]))
all_discont <- unique(c(t1_discont,t2_discont))
```

```{r echo=FALSE,include=FALSE}
# Demographics
dem_vars <- c("hba1c_baseline","demographics_age","demographics_t1d_duration","demographics_ethnicity","demographics_race","demographics_sex","demographics_insurance","demographics_pumphx","demographics_cgmhx")
demographics <- read.csv(paste0(pathstart,"som/PEDS/RI Biostatistics Core/Shared/Shared Projects/Laura/BDC/Projects/Cari Berget/6 Month Manuscript/Data_Cleaned/670GChild_GlycemicDATA_2019-01-07_.csv"))
demographics <- demographics %>%
  select(record_id,dem_vars,hba1c_baseline)
demographics[,5:ncol(demographics)] <- lapply(demographics[,5:ncol(demographics)],as.factor)
demographics$Discontinued <- ifelse(demographics$record_id %in% all_discont,"Yes","No")
demographics$age_group <- cut(demographics$demographics_age, 
                              breaks = c(0,14,18,Inf),
                              labels = c("< 14","14 - 17","18 +"),right = F)
dem_vars <- c(dem_vars,"age_group")
# Add days between visits
dates <- read.csv(paste0(pathstart,"som/PEDS/RI Biostatistics Core/Shared/Shared Projects/Laura/BDC/Projects/Cari Berget/6 Month Manuscript/Data_Cleaned/670GChild_GlycemicDATA_2019-01-07_.csv"),na.strings = "") 
# Never trained on AM
never_trained <- dates$record_id[which(is.na(dates$automode_start))]
# Remove participant 10 from discontinuers, because she had AM > 10 at T2. Also remove those never trained on AM from discontinuers
all_discont <- all_discont[-c(which(all_discont %in% c("10")))] # add never_trained to this vector
# Format
dates <- dates %>%
  select(record_id,hba1c_date_b,automode_start,t1_date_m1,t1_date,t2_date)
dates[,2:ncol(dates)] <- lapply(dates[,2:ncol(dates)],lubridate::mdy)
dates$baseline_a1c_to_am <- as.numeric(difftime(dates$automode_start,dates$hba1c_date_b),"days")
dates$am_to_m1 <- as.numeric(difftime(dates$t1_date_m1,dates$automode_start),"days")
dates$am_to_t1 <- as.numeric(difftime(dates$t1_date,dates$automode_start),"days")
dates$am_to_t2 <- as.numeric(difftime(dates$t2_date,dates$automode_start),"days")
dates <- dates %>%
  select(record_id,baseline_a1c_to_am,am_to_m1,am_to_t1,am_to_t2)
# Merge
demographics <- left_join(demographics,dates)
# Variables
dem_vars <- c("baseline_a1c_to_am","am_to_m1","am_to_t1","am_to_t2",dem_vars)
# Normality check
nonnormal <- norm.check(demographics,c("hba1c_baseline","baseline_a1c_to_am",
                                       "am_to_m1","am_to_t1","am_to_t2",
                                       "demographics_age","demographics_t1d_duration"))
# Full cohort T1 (age and T1D duration normally dist.)
t1_full <- CreateTableOne(dem_vars,data = demographics)
t1_full <- print(t1_full,nonnormal = nonnormal)
# Add age range
t1_full["demographics_age (mean (SD))",] <- 
  paste0(t1_full["demographics_age (mean (SD))",]," [",
         min(demographics$demographics_age,na.rm = T),", ",
         max(demographics$demographics_age,na.rm = T),"]")
rownames(t1_full)[which(rownames(t1_full) == "demographics_age (mean (SD))")] <-
  "demographics_age (mean (SD) [range])"
# By continuation status
t1_groups <- CreateTableOne(dem_vars,strata = "Discontinued",data = demographics)
t1_groups <- print(t1_groups,nonnormal = nonnormal,exact = c("demographics_ethnicity",
                                       "demographics_race","demographics_insurance",
                                       "demographics_pumphx","demographics_cgmhx"))
# Add age range
t1_groups["demographics_age (mean (SD))","No"] <- 
  paste0(t1_groups["demographics_age (mean (SD))","No"]," [",
         min(demographics$demographics_age[demographics$Discontinued == "No"],na.rm = T),", ",
         max(demographics$demographics_age[demographics$Discontinued == "No"],na.rm = T),"]")
t1_groups["demographics_age (mean (SD))","Yes"] <- 
  paste0(t1_groups["demographics_age (mean (SD))","Yes"]," [",
         min(demographics$demographics_age[demographics$Discontinued == "Yes"],na.rm = T),", ",
         max(demographics$demographics_age[demographics$Discontinued == "Yes"],na.rm = T),"]")
rownames(t1_groups)[which(rownames(t1_groups) == "demographics_age (mean (SD))")] <-
  "demographics_age (mean (SD) [range])"
```

## Table 1a: Descriptive Statistics, Full Cohort
```{r echo=FALSE}
kable(t1_full)
```

## Table 1b: Descriptive Statistics, by Discontinued = Yes or No
```{r echo=FALSE}
kable(t1_groups)
```

## Figure 1a: HbA1c by Timepoint, Grouped by Clinical HbA1c Cutoffs at Baseline
```{r echo=FALSE,warning=FALSE,dpi=600}
# Add baseline age to all data.
alldata$record_id <- as.character(alldata$record_id)
demographics$record_id <- as.character(demographics$record_id)
alldata <- left_join(alldata,demographics[,c("record_id","age_group")],by = "record_id")
alldata$record_id <- as.factor(alldata$record_id)
# Remove M1, group by clinical A1c cutoffs at baseline
data_no_m1 <- alldata %>%
  filter(tpoint != "M1",!(record_id %in% all_discont)) %>%
  mutate(hba1c_clinical = cut(baseline_a1c,breaks = c(0,7.5,9.0,Inf)))
# Remove B (e.g. for % time AM models etc.)
data_no_b <- alldata %>%
  filter(tpoint != "B",!(record_id %in% all_discont))
# By clinical groups
a1c_plot_clin <- 
  ggplot(data_no_m1,aes_string(x = "tpoint",y = "hba1c",group = "record_id")) + 
  geom_line(size = 0.2,aes(color = hba1c_clinical)) +
  xlab("Timepoint") + 
  ylab("HbA1c (%)") + 
  theme(legend.title=element_blank()) +
  scale_color_discrete(limits = c("(9,Inf]","(7.5,9]","(0,7.5]"))
a1c_plot_clin
```

In the above figure, a square bracket indicates that the number is included in the range. For example, (0,7.5] means that baseline HbA1c was less than or equal to 7.5, while (0,7.5) would indicate that baseline HbA1c was strictly less than 7.5.

## Figure 1b: HbA1c by Timepoint, Grouped by Age at Baseline
```{r echo=FALSE,warning=FALSE,dpi=600}
# By age group
a1c_plot_age <- 
  ggplot(data_no_m1,aes_string(x = "tpoint",y = "hba1c",group = "record_id")) + 
  geom_line(size = 0.2,aes(color = age_group)) +
  xlab("Timepoint") + 
  ylab("HbA1c (%)") +
  theme(legend.title=element_blank()) +
  scale_color_discrete(limits = c("< 14","14 - 17","18 +"))
a1c_plot_age
```

## Figure 1c: Mean HbA1c by Timepoint
```{r echo=FALSE,warning=FALSE,dpi=600}
a1c_overall <- 
  ggplot(data_no_m1,aes_string(x = "tpoint",y = "hba1c")) + 
  geom_point(size = 0.2) +
  stat_summary(fun.y=mean, colour="red", geom="point") +
  stat_summary(fun.y=mean, colour="red", geom="line", aes(group = 1)) +
  xlab("Timepoint") + 
  ylab("HbA1c (%)") +
  theme(legend.title=element_blank())
a1c_overall
```

## Table 2: A1c Mixed Models

```{r echo=FALSE, include=FALSE}
# A1c mixed models
a1c_mod <- lme(hba1c ~ tpoint*age_group*hba1c_clinical,random=~1|record_id,data = data_no_m1,na.action = na.omit)
a1c_mod_cont <- lme(hba1c ~ as.numeric(tpoint)*age_group*hba1c_clinical,random=~1|record_id,data = data_no_m1,na.action = na.omit) 
# Categorical is better
# Means model
a1c_mod_means <- lme(hba1c ~ tpoint*age_group*hba1c_clinical-1,random=~1|record_id,data = data_no_m1,na.action = na.omit)
```

```{r echo=FALSE}
kable(summary(a1c_mod)$tTable,caption = "Fixed Effects")
kable(anova.lme(a1c_mod),caption = "Type 3 Tests of Fixed Effects")
```

### Mixed model interpretation
The interpretation of fixed effects for a mixed model is the same as the interpretation for a simple linear model. The first table above shows the difference between baseline and T1 and baseline and T2. The intercept is the mean at baseline, and the values for each timepoint are the average difference from baseline. So, on average HbA1c decreased by 0.38 from baseline to T1 and by 0.22 from baseline to T2. Both of these differences were statistically significant at the 0.05 level.

The type 3 tests of fixed effects show that timepoint overall was significant.

The third table simply shows the mean HbA1c at each timepoint. The p values in this table indicate whether the mean HbA1c was significantly different from 0, so are probably not worth reporting.  

The interpretation is the same for the following tables.

## Table 3: TIR

```{r echo=FALSE}
tir_mod <- lme(sensor_70_180 ~ tpoint,random=~1|record_id,data = data_no_m1,na.action = na.omit)
# Means model
tir_mod_means <- lme(sensor_70_180 ~ tpoint-1,random=~1|record_id,data = data_no_m1,na.action = na.omit)
```

```{r echo=FALSE}
kable(summary(tir_mod)$tTable,caption = "Fixed Effects")
kable(anova.lme(tir_mod),caption = "Type 3 Tests of Fixed Effects")
kable(summary(tir_mod_means)$tTable,caption = "Timepoint Means")
```

## Table 4: AM Time

```{r echo=FALSE}
am_mod <- lme(am_time ~ tpoint,random=~1|record_id,data = data_no_b,na.action = na.omit)
# Means model
am_mod_means <- lme(am_time ~ tpoint-1,random=~1|record_id,data = data_no_b,na.action = na.omit)
```

```{r echo=FALSE}
kable(summary(am_mod)$tTable,caption = "Fixed Effects")
kable(anova.lme(am_mod),caption = "Type 3 Tests of Fixed Effects")
kable(summary(am_mod_means)$tTable,caption = "Timepoint Means")
```

## Table 5: Sensor Wear

```{r echo=FALSE}
sensor_wear_mod <- lme(sensor_wear ~ tpoint,random=~1|record_id,data = data_no_m1,na.action = na.omit)
# Means model
sensor_wear_mod_means <- lme(sensor_wear ~ tpoint-1,random=~1|record_id,data = data_no_m1,na.action = na.omit)
```

```{r echo=FALSE}
kable(summary(sensor_wear_mod)$tTable,caption = "Fixed Effects")
kable(anova.lme(sensor_wear_mod),caption = "Type 3 Tests of Fixed Effects")
kable(summary(sensor_wear_mod_means)$tTable,caption = "Timepoint Means")
```

## Table 6: AM Exits Per Day

```{r echo=FALSE}
amexit_day_mod <- lme(amexit_day ~ tpoint,random=~1|record_id,data = data_no_b,na.action = na.omit)
# Means model
amexit_day_mod_means <- lme(amexit_day ~ tpoint-1,random=~1|record_id,data = data_no_b,na.action = na.omit)
```

```{r echo=FALSE}
kable(summary(amexit_day_mod)$tTable,caption = "Fixed Effects")
kable(anova.lme(amexit_day_mod),caption = "Type 3 Tests of Fixed Effects")
kable(summary(amexit_day_mod_means)$tTable,caption = "Timepoint Means")
```

## Table 7: BG Checks

```{r echo=FALSE}
bg_checks_mod <- lme(bg_checks ~ tpoint,random=~1|record_id,data = data_no_m1,na.action = na.omit)
# Means model
bg_checks_mod_means <- lme(bg_checks ~ tpoint-1,random=~1|record_id,data = data_no_m1,na.action = na.omit)
```

```{r echo=FALSE}
kable(summary(bg_checks_mod)$tTable,caption = "Fixed Effects")
kable(anova.lme(bg_checks_mod),caption = "Type 3 Tests of Fixed Effects")
kable(summary(bg_checks_mod_means)$tTable,caption = "Timepoint Means")
```

## Table 8: Calibrations

```{r echo=FALSE}
calibrations_mod <- lme(calibrations ~ tpoint,random=~1|record_id,data = data_no_m1,na.action = na.omit)
# Means model
calibrations_mod_means <- lme(calibrations ~ tpoint-1,random=~1|record_id,data = data_no_m1,na.action = na.omit)
```

```{r echo=FALSE}
kable(summary(calibrations_mod)$tTable,caption = "Fixed Effects")
kable(anova.lme(calibrations_mod),caption = "Type 3 Tests of Fixed Effects")
kable(summary(calibrations_mod_means)$tTable,caption = "Timepoint Means")
```

## Table 9: TDD

```{r echo=FALSE}
tdd_mod <- lme(tdd ~ tpoint,random=~1|record_id,data = data_no_m1,na.action = na.omit)
# Means model
tdd_mod_means <- lme(tdd ~ tpoint-1,random=~1|record_id,data = data_no_m1,na.action = na.omit)
```

```{r echo=FALSE}
kable(summary(tdd_mod)$tTable,caption = "Fixed Effects")
kable(anova.lme(tdd_mod),caption = "Type 3 Tests of Fixed Effects")
kable(summary(tdd_mod_means)$tTable,caption = "Timepoint Means")
```

## Table 9: Basal

```{r echo=FALSE}
basal_mod <- lme(basal ~ tpoint,random=~1|record_id,data = data_no_m1,na.action = na.omit)
# Means model
basal_mod_means <- lme(basal ~ tpoint-1,random=~1|record_id,data = data_no_m1,na.action = na.omit)
```

```{r echo=FALSE}
kable(summary(basal_mod)$tTable,caption = "Fixed Effects")
kable(anova.lme(basal_mod),caption = "Type 3 Tests of Fixed Effects")
kable(summary(basal_mod_means)$tTable,caption = "Timepoint Means")
```

## Table 10: Bolus

```{r echo=FALSE}
bolus_mod <- lme(bolus ~ tpoint,random=~1|record_id,data = data_no_m1,na.action = na.omit)
# Means model
bolus_mod_means <- lme(bolus ~ tpoint-1,random=~1|record_id,data = data_no_m1,na.action = na.omit)
```

```{r echo=FALSE}
kable(summary(bolus_mod)$tTable,caption = "Fixed Effects")
kable(anova.lme(bolus_mod),caption = "Type 3 Tests of Fixed Effects")
kable(summary(bolus_mod_means)$tTable,caption = "Timepoint Means")
```

## Table 11: Model Summary

```{r echo=FALSE}
# Make table
mod_summary <- as.data.frame(matrix(nrow = 10,ncol = 4))
colnames(mod_summary) <- c("Baseline","Month 1","Time 1","Time 2")
rownames(mod_summary) <- c("HbA1c","TIR","AM Time","Sensor Wear",
                           "AM Exits Per Day","BG Checks","Calibrations","TDD",
                           "Basal","Bolus")
# A1c
a1c <- round(summary(a1c_mod_means)$tTable[,1],3)
mod_summary["HbA1c","Baseline"] <- a1c[1]
mod_summary["HbA1c",c("Time 1","Time 2")] <- 
  paste0(a1c[2:3]," (",format.pval(summary(a1c_mod)$tTable[2:3,5],eps = 0.001,digits = 2),")")
# TIR
tir <- round(summary(tir_mod_means)$tTable[,1],3)
mod_summary["TIR","Baseline"] <- tir[1]
mod_summary["TIR",c("Time 1","Time 2")] <- 
  paste0(tir[2:3]," (",format.pval(summary(tir_mod)$tTable[2:3,5],eps = 0.001,digits = 2),")")
# AM time
am <- round(summary(am_mod_means)$tTable[,1],3)
mod_summary["AM Time","Month 1"] <- am[1]
mod_summary["AM Time",c("Time 1","Time 2")] <- 
  paste0(am[2:3]," (",format.pval(summary(am_mod)$tTable[2:3,5],eps = 0.001,digits = 2),")")
# Sensor
sensor_wear <- round(summary(sensor_wear_mod_means)$tTable[,1],3)
mod_summary["Sensor Wear","Baseline"] <- sensor_wear[1]
mod_summary["Sensor Wear",c("Time 1","Time 2")] <- 
  paste0(sensor_wear[2:3]," (",format.pval(summary(sensor_wear_mod)$tTable[2:3,5],eps = 0.001,digits = 2),")")
# AM Exits Per Day
amexit_day <- round(summary(amexit_day_mod_means)$tTable[,1],3)
mod_summary["AM Exits Per Day","Month 1"] <- amexit_day[1]
mod_summary["AM Exits Per Day",c("Time 1","Time 2")] <- 
  paste0(amexit_day[2:3]," (",format.pval(summary(amexit_day_mod)$tTable[2:3,5],eps = 0.001,digits = 2),")")
# BG Checks
bg_checks <- round(summary(bg_checks_mod_means)$tTable[,1],3)
mod_summary["BG Checks","Baseline"] <- bg_checks[1]
mod_summary["BG Checks",c("Time 1","Time 2")] <- 
  paste0(bg_checks[2:3]," (",format.pval(summary(bg_checks_mod)$tTable[2:3,5],eps = 0.001,digits = 2),")")
# Calibrations
calibrations <- round(summary(calibrations_mod_means)$tTable[,1],3)
mod_summary["Calibrations","Baseline"] <- calibrations[1]
mod_summary["Calibrations",c("Time 1","Time 2")] <- 
  paste0(calibrations[2:3]," (",format.pval(summary(calibrations_mod)$tTable[2:3,5],eps = 0.001,digits = 2),")")
# TDD
tdd <- round(summary(tdd_mod_means)$tTable[,1],3)
mod_summary["TDD","Baseline"] <- tdd[1]
mod_summary["TDD",c("Time 1","Time 2")] <- 
  paste0(tdd[2:3]," (",format.pval(summary(tdd_mod)$tTable[2:3,5],eps = 0.001,digits = 2),")")
# Basal
basal <- round(summary(basal_mod_means)$tTable[,1],3)
mod_summary["Basal","Baseline"] <- basal[1]
mod_summary["Basal",c("Time 1","Time 2")] <- 
  paste0(basal[2:3]," (",format.pval(summary(basal_mod)$tTable[2:3,5],eps = 0.001,digits = 2),")")
# Bolus
bolus <- round(summary(bolus_mod_means)$tTable[,1],3)
mod_summary["Bolus","Baseline"] <- bolus[1]
mod_summary["Bolus",c("Time 1","Time 2")] <- 
  paste0(bolus[2:3]," (",format.pval(summary(bolus_mod)$tTable[2:3,5],eps = 0.001,digits = 2),")")
# Print
options(knitr.kable.NA = '')
kable(mod_summary)
```

Reported as mean (p value indicating difference from baseline or month 1)

## Figure 2: PAID by Timepoint
```{r echo=FALSE,warning=FALSE,dpi=600}
# Make a new dataframe
paid_plot_data <- data_no_m1 %>%
  select(record_id,tpoint,cpaid_score,yapaid_score)
paid_plot_data$score <- pmax(paid_plot_data$cpaid_score,paid_plot_data$yapaid_score,na.rm = T)
paid_plot_data$group <- ifelse(!is.na(paid_plot_data$cpaid_score),"Kids",ifelse(!is.na(paid_plot_data$yapaid_score),"YA",NA))
paid_plot_data <- paid_plot_data[,c("record_id","tpoint","score","group")]

parent_paid <- data_no_m1 %>%
  select(record_id,tpoint,ppaid_score)
parent_paid$record_id <- paste0(parent_paid$record_id,"p")
colnames(parent_paid) <- c("record_id","tpoint","score")
parent_paid$group <- "Parents"

paid_plot_data <- rbind(paid_plot_data,parent_paid)

paid_plot <- 
  ggplot(paid_plot_data,aes(x = tpoint,y = score,group = record_id)) + 
  geom_point(size = 0.2,aes(color = group)) +
  stat_summary(fun.y=mean, geom="line", aes(group = group,color = group)) +
  xlab("Timepoint") + 
  ylab("PAID Score") +
  theme(legend.title=element_blank()) +
  scale_color_discrete(limits = c("Parents","YA","Kids"))
paid_plot
```

## Figure 3: FOH by Timepoint
```{r echo=FALSE,warning=FALSE,dpi=600}
# Make a new dataframes for each age group
foh_p_data <- data_no_m1 %>%
  select(record_id,tpoint,pmaintain_score,phelpless_score,pworry_score)
foh_p_data <- melt(foh_p_data,id.vars = c("record_id","tpoint"))

foh_c_data <- data_no_m1 %>%
  select(record_id,tpoint,cmaintain_score,chelpless_score,cworry_score)
foh_c_data <- melt(foh_c_data,id.vars = c("record_id","tpoint"))

foh_ya_data <- data_no_m1 %>%
  select(record_id,tpoint,yabehavior_score,yaworry_score)
foh_ya_data <- melt(foh_ya_data,id.vars = c("record_id","tpoint"))
# Plot parents, lines for each individual
foh_p_plot <- ggplot(foh_p_data,aes(x=tpoint,y=value,color = variable,group=interaction(record_id,variable))) +
  geom_line() +
  ggtitle("Parents") +
  xlab("Timepoint") + 
  ylab("FOH Score") +
  labs(color='FOH Subscale')  +
  scale_color_discrete(labels = c("Maintain","Helpless","Worry"))
foh_p_plot
# Points and means
foh_p_plot <- ggplot(foh_p_data,aes(x=tpoint,y=value,color = variable)) + 
  geom_point(size = 0.2) +
  stat_summary(fun.y=mean, geom="line", aes(group = variable)) +
  ggtitle("Parents") +
  xlab("Timepoint") + 
  ylab("FOH Score") +
  labs(color='FOH Subscale') +
  scale_color_discrete(labels = c("Maintain","Helpless","Worry"))
foh_p_plot # this looks better, so will do this for other plots.
# Kids
foh_c_plot <- ggplot(foh_c_data,aes(x=tpoint,y=value,color = variable)) + 
  geom_point(size = 0.2) +
  stat_summary(fun.y=mean, geom="line", aes(group = variable)) +
  ggtitle("Kids") +
  xlab("Timepoint") + 
  ylab("FOH Score") +
  labs(color='FOH Subscale') +
  scale_color_discrete(labels = c("Maintain","Helpless","Worry"))
foh_c_plot
# YA
foh_ya_plot <- ggplot(foh_ya_data,aes(x=tpoint,y=value,color = variable)) + 
  geom_point(size = 0.2) +
  stat_summary(fun.y=mean, geom="line", aes(group = variable)) +
  ggtitle("YA") +
  xlab("Timepoint") + 
  ylab("FOH Score") +
  labs(color='FOH Subscale') +
  scale_color_discrete(labels = c("Behavior","Worry"))
foh_ya_plot
```

```{r eval=FALSE,include=FALSE}
# General notes
# During 4/12/19 meeting we decided that adjusting the models for baseline value
# doesn't really answer the scientific question. Also Cari would like to compare
# baseline to 3 month and 6 month. Month 1 A1c overlaps too much with baseline. 
# Briggs also requested new figures grouped by glycemic control (7.5, 9.0, and 
# above, plus tertiles/quartiles).

# Tried to plot three FOH subscales for parents and kids together, but the plot 
# was really messy, so split the plots by age group.
```